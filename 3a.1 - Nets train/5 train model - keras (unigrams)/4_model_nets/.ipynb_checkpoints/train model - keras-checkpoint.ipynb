{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Keras \n",
    "# Classifier: LSTM \n",
    "# Classification type: multi-class (404 classes)\n",
    "# Output nodes: #of classes with softmax\n",
    "\n",
    "# word2vec model: \n",
    "# word2vect_class_specififc__vec64_win1__dict_sample_5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing process_string.py \n",
      "from /Users/altay.amanbay/Desktop/new node booster/experiments/3a.1 - Nets train/5 train model - keras/2_common_aux_script ...\n",
      "\n",
      "3.5.2 |Anaconda 4.2.0 (x86_64)| (default, Jul  2 2016, 17:52:12) \n",
      "[GCC 4.2.1 Compatible Apple LLVM 4.2 (clang-425.0.28)]\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "from keras.datasets import reuters\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.models import load_model, Sequential\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Dense, Dropout, Activation, LSTM, Bidirectional\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.text import Tokenizer, one_hot, text_to_word_sequence\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "from keras.utils.visualize_util import plot\n",
    "from IPython.display import SVG\n",
    "from keras.utils.visualize_util import model_to_dot\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# import custom code\n",
    "import os\n",
    "import sys\n",
    "pardir = os.path.abspath(os.path.join(os.getcwd(), '../'))\n",
    "script_path = pardir + \"/2_common_aux_script\"\n",
    "print('Importing process_string.py \\nfrom ' + script_path + \" ...\\n\")\n",
    "sys.path.append(script_path)\n",
    "from process_string import process_string\n",
    "sys.path.remove(script_path)\n",
    "\n",
    "\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Functions\n",
    "\n",
    "def NGramGenerator_wordwise_interval(phrase, min_ngram, max_ngram):\n",
    "    all_ngram_lists = []\n",
    "\n",
    "    #printable_ = 'abcdefghijklmnopqrstuvwxyz0123456789 '\n",
    "    #s_split = \"\".join((char if char in printable_ else \"\") for char in phrase).split()\n",
    "    phrase_processed = process_string(phrase)\n",
    "    s_split = phrase_processed.split()\n",
    "    \n",
    "    for n in range(max_ngram, min_ngram - 1, -1):\n",
    "        n_gram = [s_split[i:i+n] for i in range(len(s_split)-n+1)]\n",
    "        all_ngram_lists.extend(n_gram)\n",
    "        \n",
    "    all_ngrams = []\n",
    "    for n_gram in all_ngram_lists:\n",
    "        all_ngrams.extend([' '.join(n_gram)])\n",
    "    \n",
    "    return all_ngrams\n",
    "\n",
    "def get_word2index(texts_ls_):\n",
    "    word2index_ = {}\n",
    "\n",
    "    c = 1\n",
    "    for text_str in texts_ls_:\n",
    "        text_tokens_ls = text_str.lower().split()\n",
    "        for token in text_tokens_ls:\n",
    "            if(token not in word2index_):\n",
    "                word2index_[token] = c\n",
    "                c = c + 1\n",
    "                \n",
    "    return word2index_\n",
    "\n",
    "def train_df_preprocess(top_words_, texts_ls_, max_pad_length_):\n",
    "    # texts_ls_: list of texts strings\n",
    "    \n",
    "    tok = Tokenizer(top_words_)\n",
    "    tok.fit_on_texts(texts_ls_)\n",
    "\n",
    "    words = []\n",
    "    for iter in range(top_words):\n",
    "        words += [key for key,value in tok.word_index.items() if value==iter+1]\n",
    "\n",
    "    #Class for vectorizing texts, or/and turning texts into sequences \n",
    "    #(=list of word indexes, where the word of rank i in the dataset (starting at 1) has index i).\n",
    "    texts_vec_ls = tok.texts_to_sequences(texts_ls_)#turns text to sequence, stating which word comes in what place\n",
    "    texts_vec_mtx = sequence.pad_sequences(texts_vec_ls, maxlen=max_pad_length_)#pad sequence, essentially padding it with 0's at the end\n",
    "    \n",
    "    return texts_vec_mtx\n",
    "\n",
    "def text_2_vec(text_str, word2index_):\n",
    "    # text_str: text string\n",
    "    \n",
    "    text_tokens_ls = text_str.lower().split()\n",
    "    \n",
    "    text_vec = []\n",
    "    for token in text_tokens_ls:\n",
    "        if token in word2index_:\n",
    "            text_vec.append(word2index_[token])\n",
    "        else:\n",
    "            text_vec.append(0)\n",
    "            \n",
    "    return text_vec\n",
    "\n",
    "def train_df_preprocess_2(texts_ls_, word2index_, max_pad_length_):\n",
    "    # texts_ls_: list of texts strings\n",
    "    \n",
    "    texts_vec_ls = []\n",
    "    for text_ in texts_ls_:\n",
    "        #print(text_)\n",
    "        #print(type(text_))\n",
    "        text_vec = text_2_vec(text_, word2index_)\n",
    "        texts_vec_ls.append(text_vec)\n",
    "    \n",
    "    texts_vec_ary = sequence.pad_sequences(texts_vec_ls, maxlen=max_pad_length_)\n",
    "    \n",
    "    return texts_vec_ary\n",
    "\n",
    "def texts_to_sequences_custom(texts_ls, word_index_):\n",
    "    texts_seq = []\n",
    "    \n",
    "    for text in texts_ls:\n",
    "        #text_split = text.lower().split()\n",
    "        text_split = NGramGenerator_wordwise_interval(text,1,1)\n",
    "        seq = []\n",
    "        for token in text_split:\n",
    "            if(token in word_index_):\n",
    "                seq.append(word_index_[token])\n",
    "            else:\n",
    "                seq.append(0)\n",
    "                \n",
    "        texts_seq.append(seq)\n",
    "#         for k,v in word_index_.items():\n",
    "#             if(v == 395):\n",
    "#                 print(k,v)\n",
    "    return texts_seq\n",
    "\n",
    "\n",
    "def get_model_file_aux(model_file_aux_name):\n",
    "    with open(model_file_aux_name, 'rb') as pickle_file:\n",
    "        model_file_aux = pickle.load(pickle_file)\n",
    "    return model_file_aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples data shape: (956776, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_mod1</th>\n",
       "      <th>category_id_mod1</th>\n",
       "      <th>category_full_path_mod1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>!iT Jeans Maternity Skinny Jeans Dark Wash M</td>\n",
       "      <td>100</td>\n",
       "      <td>Apparel &amp; Accessories &gt; Apparel &gt; Maternity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1822 Denim 'Butter' Maternity Skinny Jeans Rin...</td>\n",
       "      <td>100</td>\n",
       "      <td>Apparel &amp; Accessories &gt; Apparel &gt; Maternity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25 J Brand Maternity Skinny Jean nirvana blue</td>\n",
       "      <td>100</td>\n",
       "      <td>Apparel &amp; Accessories &gt; Apparel &gt; Maternity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26 J Brand Maternity Skinny Jean nirvana blue</td>\n",
       "      <td>100</td>\n",
       "      <td>Apparel &amp; Accessories &gt; Apparel &gt; Maternity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26 James Jeans Maternity Skinny External Mater...</td>\n",
       "      <td>100</td>\n",
       "      <td>Apparel &amp; Accessories &gt; Apparel &gt; Maternity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    description_mod1  category_id_mod1  \\\n",
       "0       !iT Jeans Maternity Skinny Jeans Dark Wash M               100   \n",
       "1  1822 Denim 'Butter' Maternity Skinny Jeans Rin...               100   \n",
       "2      25 J Brand Maternity Skinny Jean nirvana blue               100   \n",
       "3      26 J Brand Maternity Skinny Jean nirvana blue               100   \n",
       "4  26 James Jeans Maternity Skinny External Mater...               100   \n",
       "\n",
       "                       category_full_path_mod1  \n",
       "0  Apparel & Accessories > Apparel > Maternity  \n",
       "1  Apparel & Accessories > Apparel > Maternity  \n",
       "2  Apparel & Accessories > Apparel > Maternity  \n",
       "3  Apparel & Accessories > Apparel > Maternity  \n",
       "4  Apparel & Accessories > Apparel > Maternity  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read sampled descriptionary\n",
    "\n",
    "path = pardir+'/1_data/'\n",
    "file_name = 'sampled_descriptionary_sample_size_5000.csv'\n",
    "samples_df = pd.read_csv(path + file_name)\n",
    "\n",
    "# Rename columns\n",
    "samples_df.rename(columns={'description': 'description_mod1', \n",
    "                           'category_id': 'category_id_mod1',\n",
    "                           'category_path': 'category_full_path_mod1'}, inplace=True)\n",
    "\n",
    "# Drop 'screwdrivers' from descriptionary\n",
    "#samples_df = samples_df.loc[samples_df.category_id_mod1 != 927,:]\n",
    "\n",
    "# Drop index column\n",
    "samples_df.drop(labels=['index'], axis=1, inplace=True)\n",
    "\n",
    "print('samples data shape:',samples_df.shape)\n",
    "samples_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data shape (deduplicate): (947643, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_mod1</th>\n",
       "      <th>category_id_mod1</th>\n",
       "      <th>category_full_path_mod1</th>\n",
       "      <th>target_le</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>it jeans maternity skinny jeans dark wash m</td>\n",
       "      <td>100</td>\n",
       "      <td>Apparel &amp; Accessories &gt; Apparel &gt; Maternity</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1822 denim butter maternity skinny jeans rinse...</td>\n",
       "      <td>100</td>\n",
       "      <td>Apparel &amp; Accessories &gt; Apparel &gt; Maternity</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    description_mod1  category_id_mod1  \\\n",
       "0        it jeans maternity skinny jeans dark wash m               100   \n",
       "1  1822 denim butter maternity skinny jeans rinse...               100   \n",
       "\n",
       "                       category_full_path_mod1  target_le  \n",
       "0  Apparel & Accessories > Apparel > Maternity         28  \n",
       "1  Apparel & Accessories > Apparel > Maternity         28  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concat original train set and sampled descriptionary\n",
    "#train_df = pd.concat([train_df, samples_df], axis=0)\n",
    "train_df = samples_df\n",
    "#train_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# description into chars\n",
    "train_df['description_mod1'] = train_df['description_mod1'].apply(lambda x: process_string(x))\n",
    "\n",
    "# deduplicate\n",
    "train_df.drop_duplicates(subset=['description_mod1'], inplace = True)\n",
    "print('train data shape (deduplicate):',train_df.shape)\n",
    "    \n",
    "# Encode target feature\n",
    "le = LabelEncoder()\n",
    "le.fit(train_df['category_full_path_mod1'])\n",
    "train_df['target_le'] = le.transform(train_df['category_full_path_mod1'])\n",
    "\n",
    "\n",
    "train_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "663350\n",
      "284293\n",
      "(663350, 404)\n",
      "(284293, 404)\n"
     ]
    }
   ],
   "source": [
    "# Split into train and test\n",
    "#X = train_df.loc[:,['description_mod1']]\n",
    "X_ls = np.array(list(train_df['description_mod1']))\n",
    "y_ary = np.array(list(train_df['target_le']))\n",
    "y_ary_cat = np_utils.to_categorical(train_df['target_le'])\n",
    "# X_ls = train_df[['description_mod1']]\n",
    "# y_ary = train_df[['target_le']]\n",
    "\n",
    "print(type(X_ls))\n",
    "#print(type(y_ary))\n",
    "print(type(y_ary_cat))\n",
    "\n",
    "#X_train_ls, X_test_ls, y_train_ary, y_test_ary = train_test_split(X_ls, y_ary, test_size = 0.3)\n",
    "X_train_ls, X_test_ls, y_train_ary, y_test_ary = train_test_split(X_ls, y_ary_cat, test_size = 0.3)\n",
    "\n",
    "# print(X_train_df.shape)\n",
    "# print(X_test_df.shape)\n",
    "print(len(X_train_ls))\n",
    "print(len(X_test_ls))\n",
    "print(y_train_ary.shape)\n",
    "#print(y_test_ary.shape)\n",
    "print(y_test_ary.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_index size: 235349\n",
      "train_texts_vec_mtx shape: (663350, 30)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['100041', 'blackcloud', 'laurenshirt', 'bentonite', 'arundel']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert train set into sequences for nets\n",
    "\n",
    "top_words = None\n",
    "max_description_length = 30\n",
    "\n",
    "tok = Tokenizer(nb_words = top_words)\n",
    "tok.fit_on_texts(X_ls)\n",
    "word_index = tok.word_index\n",
    "print('word_index size:',len(word_index))\n",
    "\n",
    "#train_texts_vec_ls = tok.texts_to_sequences(X_train_ls)\n",
    "train_texts_vec_ls = texts_to_sequences_custom(X_train_ls, word_index)\n",
    "train_texts_vec_mtx = sequence.pad_sequences(train_texts_vec_ls, maxlen = max_description_length)\n",
    "\n",
    "print('train_texts_vec_mtx shape:',train_texts_vec_mtx.shape)\n",
    "list(tok.word_index)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert test set into sequences for nets\n",
    "\n",
    "#test_texts_vec_ls = tok.texts_to_sequences(X_test_ls)\n",
    "test_texts_vec_ls = texts_to_sequences_custom(X_test_ls, word_index)\n",
    "test_texts_vec_mtx = sequence.pad_sequences(test_texts_vec_ls, maxlen = max_description_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mouth watchers mouth watchers antibacterial youth toothbrush pink\n",
      "[2090, 11972, 2090, 11972, 1293, 578, 162, 80]\n",
      "[    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0  2090 11972\n",
      "  2090 11972  1293   578   162    80]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "235349"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test check\n",
    "i = 100\n",
    "print(X_train_ls[i])\n",
    "print(train_texts_vec_ls[i])\n",
    "print(train_texts_vec_mtx[i])\n",
    "len(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 235761 word vectors.\n",
      "embedding_vecor_length: 64\n",
      "\n",
      "embedding matrix shape: (235350, 64)\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[-0.06146404  0.081076    0.00112323  0.04499147  0.1002018   0.01332603\n",
      " -0.19582143 -0.03727768  0.08618295 -0.24972945 -0.06021989  0.28060985\n",
      "  0.08473843  0.04667721  0.13200024 -0.15039206  0.00561094 -0.21778092\n",
      " -0.09161391  0.0259797  -0.11244918 -0.01754784 -0.08015888 -0.11885061\n",
      "  0.13581887 -0.08760685  0.05284847  0.12670977 -0.05489041  0.32682282\n",
      " -0.00553122 -0.03708532 -0.05104759  0.01759537  0.11875682  0.13249238\n",
      " -0.05064112  0.17661691  0.03251493  0.02025766  0.11108632 -0.05402073\n",
      " -0.13319896  0.0944826  -0.00662499  0.20068783  0.07138328 -0.17812581\n",
      "  0.06006688  0.06778252 -0.17951348 -0.00747066  0.01565725  0.00944159\n",
      "  0.1358608   0.18168604  0.2046535  -0.28609699  0.07989392  0.14673866\n",
      " -0.14850725  0.10774294 -0.10994995  0.10638081]\n"
     ]
    }
   ],
   "source": [
    "## Create word embeddings from trained Word2Vec model\n",
    "from gensim.models import word2vec, Phrases\n",
    "\n",
    "# Load model\n",
    "file_path_1 = pardir+\"/3_model_word2vec_vec64_win1__dict_sample_5000/word2vect_class_specififc_unigrams__vec64_win1__dict_sample_5000\"\n",
    "model = word2vec.Word2Vec.load(file_path_1)\n",
    "\n",
    "#print(model.vocab.keys())\n",
    "#sys.exit()\n",
    "\n",
    "# word vector embeddings from model into dictionary\n",
    "word2vec_dict={}\n",
    "for word in model.vocab.keys():\n",
    "    try:\n",
    "        word2vec_dict[word]=model[word]\n",
    "    except:    \n",
    "        pass\n",
    "print('Loaded %s word vectors.' % len(word2vec_dict))\n",
    "    \n",
    "embedding_vecor_length = len(model[word])\n",
    "print('embedding_vecor_length:',embedding_vecor_length)\n",
    "\n",
    "\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, embedding_vecor_length))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = word2vec_dict.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        \n",
    "print('\\nembedding matrix shape:',embedding_matrix.shape)\n",
    "print(embedding_matrix[0]) # first cell should be all zeros\n",
    "print(embedding_matrix[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Best model result holder\n",
    "best_model_aux = {}\n",
    "best_model_aux['Max length'] = max_description_length\n",
    "best_model_aux['Best Score'] = 0\n",
    "# best_model_aux['Category ID'] = 927\n",
    "# best_model_aux['Category name'] = 'Tools & Home Improvement > Power & Hand Tools > Hand Tools > Screwdrivers'\n",
    "best_model_aux['Tokenizer'] = tok\n",
    "\n",
    "best_model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Optional\n",
    "# Load previous model (if needs to be compared in the following training)\n",
    "#best_model = load_model('category_927_nets_1000_model.h5')\n",
    "#best_model_aux = get_model_file_aux('category_927_nets_1000_model_aux.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes count: 404\n"
     ]
    }
   ],
   "source": [
    "# prediction nodes count\n",
    "nb_classes = train_df['category_full_path_mod1'].unique()\n",
    "print('Classes count:', len(nb_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_3 (Embedding)          (None, 30, 64)        12221056    embedding_input_3[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional)  (None, 256)           197632      embedding_3[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                  (None, 404)           103828      bidirectional_3[0][0]            \n",
      "====================================================================================================\n",
      "Total params: 12,522,516\n",
      "Trainable params: 301,460\n",
      "Non-trainable params: 12,221,056\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "Epoch iter #1\n",
      "Train on 663350 samples, validate on 284293 samples\n",
      "Epoch 1/1\n",
      "663350/663350 [==============================] - 1619s - loss: 1.0813 - acc: 0.7165 - val_loss: 0.7447 - val_acc: 0.7878\n",
      "Captured improved model\n",
      "\n",
      "Epoch iter #2\n",
      "Train on 663350 samples, validate on 284293 samples\n",
      "Epoch 1/1\n",
      "663350/663350 [==============================] - 1701s - loss: 0.5648 - acc: 0.8342 - val_loss: 0.6065 - val_acc: 0.8242\n",
      "Captured improved model\n",
      "\n",
      "Epoch iter #3\n",
      "Train on 663350 samples, validate on 284293 samples\n",
      "Epoch 1/1\n",
      "663350/663350 [==============================] - 1660s - loss: 0.4850 - acc: 0.8547 - val_loss: 0.5705 - val_acc: 0.8349\n",
      "Captured improved model\n",
      "\n",
      "Epoch iter #4\n",
      "Train on 663350 samples, validate on 284293 samples\n",
      "Epoch 1/1\n",
      "663350/663350 [==============================] - 1656s - loss: 0.4423 - acc: 0.8665 - val_loss: 0.5252 - val_acc: 0.8444\n",
      "Captured improved model\n",
      "\n",
      "Epoch iter #5\n",
      "Train on 663350 samples, validate on 284293 samples\n",
      "Epoch 1/1\n",
      "663350/663350 [==============================] - 1642s - loss: 0.4124 - acc: 0.8745 - val_loss: 0.5131 - val_acc: 0.8496\n",
      "Captured improved model\n",
      "\n",
      "Epoch iter #6\n",
      "Train on 663350 samples, validate on 284293 samples\n",
      "Epoch 1/1\n",
      "663350/663350 [==============================] - 1623s - loss: 0.3905 - acc: 0.8804 - val_loss: 0.4992 - val_acc: 0.8532\n",
      "Captured improved model\n",
      "\n",
      "Epoch iter #7\n",
      "Train on 663350 samples, validate on 284293 samples\n",
      "Epoch 1/1\n",
      "663350/663350 [==============================] - 1609s - loss: 0.3725 - acc: 0.8855 - val_loss: 0.4799 - val_acc: 0.8581\n",
      "Captured improved model\n",
      "\n",
      "Epoch iter #8\n",
      "Train on 663350 samples, validate on 284293 samples\n",
      "Epoch 1/1\n",
      "663350/663350 [==============================] - 1609s - loss: 0.3580 - acc: 0.8893 - val_loss: 0.4969 - val_acc: 0.8549\n",
      "Training took 15034.9 s\n"
     ]
    }
   ],
   "source": [
    "# TRAIN MODEL 2\n",
    "start = time.time()\n",
    "\n",
    "# define/initialize model\n",
    "top_words = len(word_index) + 1\n",
    "batch_size_ = 64   # 64\n",
    "\n",
    "model = Sequential()\n",
    "# --------------------------------------------------------------------------------------\n",
    "# ---- Embedding layer -----------------------------------------------------------------\n",
    "embedding_layer = Embedding(top_words, \n",
    "                            embedding_vecor_length, \n",
    "                            weights=[embedding_matrix], \n",
    "                            input_length = max_description_length,\n",
    "                            trainable=False)\n",
    "model.add(embedding_layer)\n",
    "\n",
    "## LSTM 1\n",
    "## ======================================================================================\n",
    "LSTM_1 = Bidirectional(LSTM(128,return_sequences=False))\n",
    "model.add(LSTM_1)\n",
    "\n",
    "## Dense 1\n",
    "## ======================================================================================\n",
    "Dense_1 = Dense(128,activation='sigmoid')\n",
    "#model.add(Dense_1)\n",
    "\n",
    "## Output classes layer\n",
    "## ======================================================================================\n",
    "model.add(Dense(len(nb_classes), activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])  # try loss=categorical_crossentropy\n",
    "print(model.summary())\n",
    "\n",
    "# start training multiple times with epoch=1\n",
    "for ep in range(20):\n",
    "    print('Epoch iter #' + str(ep+1))\n",
    "    \n",
    "    #model.fit(X_train_ary, y_train_ary, validation_data=(X_train_ary, y_train_ary), nb_epoch=5, batch_size=64)\n",
    "    model.fit(train_texts_vec_mtx, y_train_ary, validation_data=(test_texts_vec_mtx, y_test_ary), nb_epoch=1, batch_size=batch_size_)\n",
    "    \n",
    "    scores = model.evaluate(test_texts_vec_mtx, y_test_ary, verbose=0)\n",
    "    if(best_model_aux['Best Score'] < scores[1]):\n",
    "        best_model_aux['Best Score'] = scores[1]\n",
    "        best_model = model\n",
    "        print('Captured improved model')\n",
    "        #print(\"Accuracy on test set: %.2f%%\" % (scores[1]*100))\n",
    "    else:\n",
    "        break\n",
    "    print()\n",
    " \n",
    "\n",
    "print(\"Training took %g s\" % (time.time() - start))\n",
    "\n",
    "# Accuracy: 0.85809710404406725"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85809710404406725"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_aux['Best Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_1 (Embedding)          (None, 30, 64)        15062400    embedding_input_1[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                    (None, 128)           98816       embedding_1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 404)           52116       lstm_1[0][0]                     \n",
      "====================================================================================================\n",
      "Total params: 15,213,332\n",
      "Trainable params: 150,932\n",
      "Non-trainable params: 15,062,400\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "Epoch iter #1\n",
      "Train on 663350 samples, validate on 284293 samples\n",
      "Epoch 1/1\n",
      "663350/663350 [==============================] - 1091s - loss: 1.2589 - acc: 0.6901 - val_loss: 0.6475 - val_acc: 0.8182\n",
      "Captured improved model\n",
      "\n",
      "Epoch iter #2\n",
      "Train on 663350 samples, validate on 284293 samples\n",
      "Epoch 1/1\n",
      "663350/663350 [==============================] - 1109s - loss: 0.5769 - acc: 0.8333 - val_loss: 0.5466 - val_acc: 0.8387\n",
      "Captured improved model\n",
      "\n",
      "Epoch iter #3\n",
      "Train on 663350 samples, validate on 284293 samples\n",
      "Epoch 1/1\n",
      "663350/663350 [==============================] - 1120s - loss: 0.4966 - acc: 0.8536 - val_loss: 0.4781 - val_acc: 0.8582\n",
      "Captured improved model\n",
      "\n",
      "Epoch iter #4\n",
      "Train on 663350 samples, validate on 284293 samples\n",
      "Epoch 1/1\n",
      "663350/663350 [==============================] - 1121s - loss: 0.4539 - acc: 0.8649 - val_loss: 0.4464 - val_acc: 0.8662\n",
      "Captured improved model\n",
      "\n",
      "Epoch iter #5\n",
      "Train on 663350 samples, validate on 284293 samples\n",
      "Epoch 1/1\n",
      "663350/663350 [==============================] - 1134s - loss: 0.4259 - acc: 0.8719 - val_loss: 0.4302 - val_acc: 0.8703\n",
      "Captured improved model\n",
      "\n",
      "Epoch iter #6\n",
      "Train on 663350 samples, validate on 284293 samples\n",
      "Epoch 1/1\n",
      "663350/663350 [==============================] - 1163s - loss: 0.4045 - acc: 0.8778 - val_loss: 0.4176 - val_acc: 0.8747\n",
      "Captured improved model\n",
      "\n",
      "Epoch iter #7\n",
      "Train on 663350 samples, validate on 284293 samples\n",
      "Epoch 1/1\n",
      "663350/663350 [==============================] - 1121s - loss: 0.3874 - acc: 0.8820 - val_loss: 0.4176 - val_acc: 0.8741\n",
      "Training took 8685.6 s\n"
     ]
    }
   ],
   "source": [
    "# TRAIN MODEL 1\n",
    "start = time.time()\n",
    "\n",
    "# define/initialize model\n",
    "top_words = len(word_index) + 1\n",
    "batch_size_ = 64   # 64\n",
    "\n",
    "model = Sequential()\n",
    "# --------------------------------------------------------------------------------------\n",
    "# ---- Embedding layer -----------------------------------------------------------------\n",
    "embedding_layer = Embedding(top_words, \n",
    "                            embedding_vecor_length, \n",
    "                            weights=[embedding_matrix], \n",
    "                            input_length = max_description_length,\n",
    "                            trainable=False)\n",
    "model.add(embedding_layer)\n",
    "\n",
    "## LSTM 1\n",
    "## ======================================================================================\n",
    "LSTM_1 = LSTM(128,return_sequences=False)\n",
    "model.add(LSTM_1)\n",
    "\n",
    "## Dense 1\n",
    "## ======================================================================================\n",
    "Dense_1 = Dense(128,activation='sigmoid')\n",
    "#model.add(Dense_1)\n",
    "\n",
    "## Output classes layer\n",
    "## ======================================================================================\n",
    "model.add(Dense(len(nb_classes), activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])  # try loss=categorical_crossentropy\n",
    "print(model.summary())\n",
    "\n",
    "# start training multiple times with epoch=1\n",
    "for ep in range(20):\n",
    "    print('Epoch iter #' + str(ep+1))\n",
    "    \n",
    "    #model.fit(X_train_ary, y_train_ary, validation_data=(X_train_ary, y_train_ary), nb_epoch=5, batch_size=64)\n",
    "    model.fit(train_texts_vec_mtx, y_train_ary, validation_data=(test_texts_vec_mtx, y_test_ary), nb_epoch=1, batch_size=batch_size_)\n",
    "    \n",
    "    scores = model.evaluate(test_texts_vec_mtx, y_test_ary, verbose=0)\n",
    "    if(best_model_aux['Best Score'] < scores[1]):\n",
    "        best_model_aux['Best Score'] = scores[1]\n",
    "        best_model = model\n",
    "        print('Captured improved model')\n",
    "        #print(\"Accuracy on test set: %.2f%%\" % (scores[1]*100))\n",
    "    else:\n",
    "        break\n",
    "    print()\n",
    " \n",
    "\n",
    "print(\"Training took %g s\" % (time.time() - start))\n",
    "\n",
    "# Accuracy: 0.86345777068045859"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88996915154435741"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_aux['Best Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"264pt\" viewBox=\"0.00 0.00 205.57 264.00\" width=\"206pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 260)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-260 201.5693,-260 201.5693,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 15899726624 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>15899726624</title>\n",
       "<polygon fill=\"none\" points=\"0,-219.5 0,-255.5 197.5693,-255.5 197.5693,-219.5 0,-219.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"98.7847\" y=\"-233.3\">embedding_input_1: InputLayer</text>\n",
       "</g>\n",
       "<!-- 15899726400 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>15899726400</title>\n",
       "<polygon fill=\"none\" points=\"16.7139,-146.5 16.7139,-182.5 180.8555,-182.5 180.8555,-146.5 16.7139,-146.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"98.7847\" y=\"-160.3\">embedding_1: Embedding</text>\n",
       "</g>\n",
       "<!-- 15899726624&#45;&gt;15899726400 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>15899726624-&gt;15899726400</title>\n",
       "<path d=\"M98.7847,-219.4551C98.7847,-211.3828 98.7847,-201.6764 98.7847,-192.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"102.2848,-192.5903 98.7847,-182.5904 95.2848,-192.5904 102.2848,-192.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 5021544688 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>5021544688</title>\n",
       "<polygon fill=\"none\" points=\"49.3623,-73.5 49.3623,-109.5 148.207,-109.5 148.207,-73.5 49.3623,-73.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"98.7847\" y=\"-87.3\">lstm_1: LSTM</text>\n",
       "</g>\n",
       "<!-- 15899726400&#45;&gt;5021544688 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>15899726400-&gt;5021544688</title>\n",
       "<path d=\"M98.7847,-146.4551C98.7847,-138.3828 98.7847,-128.6764 98.7847,-119.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"102.2848,-119.5903 98.7847,-109.5904 95.2848,-119.5904 102.2848,-119.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 16226858096 -->\n",
       "<g class=\"node\" id=\"node4\">\n",
       "<title>16226858096</title>\n",
       "<polygon fill=\"none\" points=\"46.6587,-.5 46.6587,-36.5 150.9106,-36.5 150.9106,-.5 46.6587,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"98.7847\" y=\"-14.3\">dense_2: Dense</text>\n",
       "</g>\n",
       "<!-- 5021544688&#45;&gt;16226858096 -->\n",
       "<g class=\"edge\" id=\"edge3\">\n",
       "<title>5021544688-&gt;16226858096</title>\n",
       "<path d=\"M98.7847,-73.4551C98.7847,-65.3828 98.7847,-55.6764 98.7847,-46.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"102.2848,-46.5903 98.7847,-36.5904 95.2848,-46.5904 102.2848,-46.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot Nets design\n",
    "#from keras.utils import plot_model\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils.visualize_util import model_to_dot\n",
    "\n",
    "plot(model, to_file='/Users/altay.amanbay/Desktop/model.png')\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save model and aux file\n",
    "\n",
    "best_model.save('nets_category_all_unigrams__traindata5000_vectrain5000_model.h5')\n",
    "\n",
    "best_model_aux_name = 'nets_category_all_unigrams__traindata5000_vectrain5000_aux.pkl'\n",
    "with open(best_model_aux_name, 'wb') as pickle_file:\n",
    "    pickle.dump(best_model_aux, pickle_file, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set: 86.66%\n",
      "Accuracy on test set: 83.86%\n",
      "\n",
      "Evaluation took 390.131 s\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of the model\n",
    "start = time.time()\n",
    "\n",
    "scores = model.evaluate(train_texts_vec_mtx, y_train_ary, verbose=0)\n",
    "print(\"Accuracy on train set: %.2f%%\" % (scores[1]*100))\n",
    "scores = model.evaluate(test_texts_vec_mtx, y_test_ary, verbose=0)\n",
    "print(\"Accuracy on test set: %.2f%%\" % (scores[1]*100))\n",
    "\n",
    "print(\"\\nEvaluation took %g s\" % (time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "284256/284293 [============================>.] - ETA: 0spredictions[0]       : 304\n",
      "\n",
      "Prediction took 242.941 s\n"
     ]
    }
   ],
   "source": [
    "# Get predictions\n",
    "start = time.time()\n",
    "\n",
    "predictions = model.predict_classes(test_texts_vec_mtx)\n",
    "#predictions_rnd = np.round_(predictions, decimals=0, out=None)\n",
    "predictions_probs = model.predict(test_texts_vec_mtx)\n",
    "\n",
    "print('%-20s' % \"predictions[0]\",':', predictions[0])\n",
    "#print('%-20s' % \"predictions_rnd[0]:\",':',predictions_rnd[0])\n",
    "#print('%-20s' % \"predictions_probs[0]\",':', predictions_probs[0])\n",
    "print(\"\\nPrediction took %g s\" % (time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tools & Home Improvement > Lighting, Light Bulbs & Ceiling Fans > Other\n",
      "[ 'progress lighting p299281 archiethree light bath vanity antique nickel finish'\n",
      " 'bulbrite 60a15f 60watt incandescent a15 appliance bulb frost'\n",
      " 'greenhouse indooroutdoor chandelier rasped iron finish' ...,\n",
      " 'ge advantage fluorescent'\n",
      " 'feit ctcdm500led 60w equivalent candelabra base torpedo tip chandelier led light soft white'\n",
      " 'alena 97 arched floor lamp by house of hampton'] \n",
      "\n",
      "Tools & Home Improvement > Lighting, Light Bulbs & Ceiling Fans > Light Fixtures & Lamps\n",
      "['cortina nightstand right door'\n",
      " 'camino vintage candelabra twotier chandelier 72'\n",
      " 'golden lighting 2501ba3' ..., 'aspect white 23 open unit'\n",
      " 'harpwell 7light oilrubbed bronze chandelier'\n",
      " 'connie 2light antique black flush mount'] \n",
      "\n",
      "Tools & Home Improvement > Lighting, Light Bulbs & Ceiling Fans > Light Bulbs\n",
      "[ '3 pack led light bulbs lohas b35 7w soft white 3000k e12 candelabra bulb equivalent to 6065 watt incandescent'\n",
      " 'br30 led bulbsluminwiz 9w 3000k 680lm soft white dimmable flood light bulb65w equivalentmedium base e26dimmableul listedenergy star pack of 4'\n",
      " 'philips 12watt 65w 420281 led br30 flood bright white 3000k light bulb'\n",
      " ...,\n",
      " '10 pack par38 led 13 watt 120w equivalent 3000k warm white dimmable indooroutdoor lighting 1050 lumens'\n",
      " '4watt 25w equivalent mr 16 gu 53 led bulb 249 lumens neutral bright 3500k  nondimmable'\n",
      " 'bulbrite industries r20 halogen reflector flood bulb'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Manual check which nodes are not distinguishable for nets\n",
    "class_ = 392\n",
    "print(le.inverse_transform(class_))\n",
    "print(X_test_ls[np_utils.categorical_probas_to_classes(y_test_ary)==class_],'\\n')\n",
    "\n",
    "class_ = 390\n",
    "print(le.inverse_transform(class_))\n",
    "print(X_test_ls[np_utils.categorical_probas_to_classes(y_test_ary)==class_],'\\n')\n",
    "\n",
    "class_ = 389\n",
    "print(le.inverse_transform(class_))\n",
    "print(X_test_ls[np_utils.categorical_probas_to_classes(y_test_ary)==class_],'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>...</th>\n",
       "      <th>389</th>\n",
       "      <th>390</th>\n",
       "      <th>392</th>\n",
       "      <th>393</th>\n",
       "      <th>394</th>\n",
       "      <th>395</th>\n",
       "      <th>396</th>\n",
       "      <th>397</th>\n",
       "      <th>403</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>1226</td>\n",
       "      <td>189</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>190</td>\n",
       "      <td>1146</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>146</td>\n",
       "      <td>311</td>\n",
       "      <td>1001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>321</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>1291</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>113</td>\n",
       "      <td>496</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>134</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1444</td>\n",
       "      <td>18</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>29</td>\n",
       "      <td>1253</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>328</td>\n",
       "      <td>294</td>\n",
       "      <td>804</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>519</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>862</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1411</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1246</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>383</td>\n",
       "      <td>0</td>\n",
       "      <td>387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>164</td>\n",
       "      <td>21</td>\n",
       "      <td>1641</td>\n",
       "      <td>1697</td>\n",
       "      <td>1157</td>\n",
       "      <td>11</td>\n",
       "      <td>370</td>\n",
       "      <td>1474</td>\n",
       "      <td>666</td>\n",
       "      <td>155</td>\n",
       "      <td>...</td>\n",
       "      <td>1832</td>\n",
       "      <td>1706</td>\n",
       "      <td>964</td>\n",
       "      <td>532</td>\n",
       "      <td>864</td>\n",
       "      <td>1424</td>\n",
       "      <td>1262</td>\n",
       "      <td>387</td>\n",
       "      <td>29</td>\n",
       "      <td>284293</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>364 rows × 330 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    1   2     3     4     5   6    9    10   11   12   ...     389  \\\n",
       "True                                                            ...           \n",
       "1          120   1    22     9     0   0    0     1    0    0   ...       0   \n",
       "2            1  18     1     0     4   0    0     0    0    0   ...       0   \n",
       "3           27   0  1226   189    70   0    0     0    0    0   ...       0   \n",
       "4            6   0   190  1146    60   0    1     2    7    0   ...       0   \n",
       "5            4   1   146   311  1001   0    0     0    0    0   ...       0   \n",
       "6            0   0     0     0     0   9    0     0    0    0   ...       0   \n",
       "9            3   0     0     1     0   0  321    31    3    0   ...       0   \n",
       "10           0   0     4     2     0   0   42  1291  146    0   ...       0   \n",
       "11           0   0     1     0     0   0    1   113  496    0   ...       0   \n",
       "12           0   0     0     0     0   0    0     0    0  134   ...       0   \n",
       "13           0   0     0     0     0   0    0     0    0    0   ...       0   \n",
       "14           0   0     0     0     0   0    0     0    0    6   ...       0   \n",
       "15           1   0     0     0     0   0    0     0    0    0   ...       0   \n",
       "16           0   0     0     0     0   0    0     0    0    0   ...       0   \n",
       "17           0   0     3     1     0   0    0     1    2    0   ...       0   \n",
       "18           0   0     0     2     0   0    0     0    0    0   ...       0   \n",
       "19           1   0     0     1     1   0    0     1    0    0   ...       0   \n",
       "20           0   0     0     0     0   0    0     0    0   14   ...       0   \n",
       "21           0   0     0     0     0   0    0     0    0    0   ...       0   \n",
       "22           0   0     0     0     0   0    0     0    0    0   ...       0   \n",
       "23           0   0     1     0     0   0    0     0    0    0   ...       0   \n",
       "24           0   0     0     0     0   0    0     0    0    1   ...       0   \n",
       "25           0   0     0     0     0   0    0     0    0    0   ...       0   \n",
       "26           0   0     0     0     0   0    0     0    0    0   ...       0   \n",
       "27           0   0     0     0     2   0    0     0    0    0   ...       0   \n",
       "28           0   0     0     0     0   0    0     0    0    0   ...       0   \n",
       "30           0   0     0     0     0   0    1     2    0    0   ...       0   \n",
       "31           0   0     0     0     0   0    0     0    0    0   ...       0   \n",
       "32           0   0     1     0     1   0    0     1    0    0   ...       0   \n",
       "33           0   0     3     2     0   0    0     0    0    0   ...       0   \n",
       "...        ...  ..   ...   ...   ...  ..  ...   ...  ...  ...   ...     ...   \n",
       "366          0   0     0     0     0   0    0     0    0    0   ...       0   \n",
       "367          0   0     0     1     0   0    0     0    0    0   ...       0   \n",
       "368          0   0     0     0     0   0    0     0    0    0   ...       0   \n",
       "369          0   0     9     3     0   0    0     0    0    0   ...       1   \n",
       "370          0   0     0     0     0   0    0     0    0    0   ...       0   \n",
       "371          0   0     0     0     0   0    0     0    0    0   ...       0   \n",
       "373          0   0     0     0     0   0    0     0    0    0   ...       0   \n",
       "376          0   0     0     0     0   0    0     0    0    0   ...       0   \n",
       "378          0   0     0     0     0   0    0     0    0    0   ...       0   \n",
       "379          0   0     0     0     0   0    0     0    0    0   ...       0   \n",
       "380          0   0     0     0     0   0    0     0    0    0   ...       0   \n",
       "381          0   0     0     0     0   0    0     0    0    0   ...       0   \n",
       "382          0   0     0     0     0   0    0     0    0    0   ...       4   \n",
       "383          0   0     0     0     0   0    0     0    0    0   ...       0   \n",
       "384          0   0     0     0     0   0    0     0    0    0   ...       0   \n",
       "385          0   0     0     0     0   0    0     0    0    0   ...       0   \n",
       "386          0   0     0     0     0   0    0     0    0    0   ...       0   \n",
       "387          0   0     0     0     0   0    0     0    0    0   ...       0   \n",
       "388          0   0     0     0     0   0    0     0    0    0   ...       0   \n",
       "389          0   0     0     0     0   0    0     0    0    0   ...    1444   \n",
       "390          0   0     1     2     0   0    0     0    0    0   ...      29   \n",
       "392          0   0     0     0     0   0    0     0    1    0   ...     328   \n",
       "393          0   0     0     0     0   0    0     0    0    0   ...       0   \n",
       "394          0   0     0     0     0   0    0     0    0    0   ...       0   \n",
       "395          0   0     0     0     0   0    0     0    0    0   ...       0   \n",
       "396          0   0     0     0     0   0    0     0    0    0   ...       0   \n",
       "397          0   0     0     0     0   0    0     0    0    0   ...       0   \n",
       "400          0   0     0     0     0   0    0     0    0    0   ...       0   \n",
       "403          0   0     0     0     0   0    0     0    0    0   ...       0   \n",
       "All        164  21  1641  1697  1157  11  370  1474  666  155   ...    1832   \n",
       "\n",
       "Predicted   390  392  393  394   395   396  397  403     All  \n",
       "True                                                          \n",
       "1             0    0    0    0     0     0    0    0     158  \n",
       "2             0    0    0    0     0     0    0    0      25  \n",
       "3             0    0    0    0     0     0    0    0    1540  \n",
       "4             0    0    0    0     0     0    0    0    1451  \n",
       "5             1    0    0    0     0     0    0    0    1493  \n",
       "6             0    0    0    0     0     0    0    0       9  \n",
       "9             0    0    0    0     0     0    0    0     367  \n",
       "10            0    0    0    0     0     0    0    0    1514  \n",
       "11            0    0    0    0     0     0    0    0     622  \n",
       "12            0    0    0    0     0     0    0    0     139  \n",
       "13            0    0    0    0     0     0    0    0      50  \n",
       "14            0    0    0    0     0     0    0    0      86  \n",
       "15            1    0    0    0     0     0    0    0    1456  \n",
       "16            1    0    0    0     0     0    0    0    1476  \n",
       "17            0    0    0    0     0     0    0    0    1570  \n",
       "18            0    0    0    0     0     0    0    0    1440  \n",
       "19            0    0    0    0     0     0    0    0    1511  \n",
       "20            0    0    0    0     0     0    0    0    1512  \n",
       "21            0    0    0    0     0     0    0    0    1474  \n",
       "22            0    0    0    0     0     0    0    0    1462  \n",
       "23            0    0    0    0     0     0    0    0    1573  \n",
       "24            0    0    0    0     0     0    0    0    1507  \n",
       "25            0    0    0    0     0     0    0    0    1323  \n",
       "26            0    0    0    0     0     0    0    0    1446  \n",
       "27            0    0    0    0     0     0    0    0    1457  \n",
       "28            0    0    0    0     0     0    0    0    1080  \n",
       "30            0    0    0    0     0     0    0    0    1441  \n",
       "31            0    0    0    0     0     0    0    0    1433  \n",
       "32            0    0    0    0     0     0    0    0    1519  \n",
       "33            1    0    0    0     0     0    0    0    1537  \n",
       "...         ...  ...  ...  ...   ...   ...  ...  ...     ...  \n",
       "366           0    0    0    0     0     0    0    0       1  \n",
       "367           0    0    0    0     0     0    0    0       9  \n",
       "368           0    0    0    0     0     0    0    0      10  \n",
       "369           0    1    0    0     0     0    0    0    1545  \n",
       "370           0    0    0    0     0     0    0    0       1  \n",
       "371           0    0    0    0     0     0    0    0       1  \n",
       "373           0    0    0    0     0     0    0    0     847  \n",
       "376           1    0    0    0     0     0    0    0     646  \n",
       "378           0    0    0    0     0     0    0    0    1512  \n",
       "379           1    0    0    0     0     0    0    0     270  \n",
       "380           1    0    0    0     0     0    0    0     619  \n",
       "381           0    0    0    0     0     0    0    0     484  \n",
       "382          23    2    0    0     0     1    0    0    1574  \n",
       "383           6    0    0    0     0     0    0    0    1212  \n",
       "384           0    0    0    0     0     0    0    0       3  \n",
       "385           0    0    0    0     0     0    0    0    1348  \n",
       "386           1    0    0    0     0     0    0    0    1500  \n",
       "387           1    0    0    0     0     1    0    0    1475  \n",
       "388           9    2    0    0     0     0    0    0    1499  \n",
       "389          18   47    1    0     0     0    0    0    1538  \n",
       "390        1253   80    0    0     1     0    0    0    1445  \n",
       "392         294  804    0    0     0     0    0    0    1471  \n",
       "393           0    0  519    0     0     0    0    0     536  \n",
       "394           0    1    0  862     1     6    0    0     885  \n",
       "395           0    0    2    1  1411     6    1    0    1451  \n",
       "396           1    0    0    0     5  1246    1    0    1271  \n",
       "397           0    0    0    0     0     1  383    0     387  \n",
       "400           0    0    0    0     0     0    0    0       1  \n",
       "403           0    0    0    0     0     0    0   10      35  \n",
       "All        1706  964  532  864  1424  1262  387   29  284293  \n",
       "\n",
       "[364 rows x 330 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pd.crosstab(pd.Series(y_test_ary.ravel()), pd.Series(predictions_rnd.ravel()), rownames=['True'], colnames=['Predicted'], margins=True)\n",
    "pd.crosstab(pd.Series(np_utils.categorical_probas_to_classes(y_test_ary)), pd.Series(predictions), rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>78363</td>\n",
       "      <td>103</td>\n",
       "      <td>78466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102</td>\n",
       "      <td>1493</td>\n",
       "      <td>1595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>78465</td>\n",
       "      <td>1596</td>\n",
       "      <td>80061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0.0   1.0    All\n",
       "True                         \n",
       "0          78363   103  78466\n",
       "1            102  1493   1595\n",
       "All        78465  1596  80061"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(pd.Series(np_utils.categorical_probas_to_classes(y_test_ary)), pd.Series(predictions.ravel()), rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#model.get_config()\n",
    "def prediction_to_str(clf_prediction, category_id):\n",
    "    if(clf_prediction > 0.5):\n",
    "        return str(category_id)\n",
    "    else:\n",
    "        return 'not ' + str(category_id)\n",
    "\n",
    "def predict(description_str, tok_, clf_, max_length_, category_id_):\n",
    "    #seq_ = tok_.texts_to_sequences([description_str])\n",
    "    seq_ = texts_to_sequences_custom([description_str.lower()], tok_.word_index)\n",
    "    seq_pad = sequence.pad_sequences(seq_, maxlen = max_length_)\n",
    "    #clf_prediction = clf_.predict(seq_pad)\n",
    "    clf_prediction = old_best_model_.predict_classes(seq_pad, verbose=0)\n",
    "    \n",
    "    #print(seq_)\n",
    "    #print(seq_pad)\n",
    "    \n",
    "    # Prediction to string\n",
    "    #clf_prediction_str = prediction_to_str(clf_prediction[0][0], category_id_)\n",
    "    clf_prediction_str = clf_prediction\n",
    "    \n",
    "    return clf_prediction_str\n",
    "    #return clf_prediction[0][0]\n",
    "\n",
    "def predict_2(description_str, tok_, clf_, max_length_, category_id_):\n",
    "    #seq_ = tok_.texts_to_sequences([description_str])\n",
    "    seq_ = texts_to_sequences_custom([description_str.lower()], tok_.word_index)\n",
    "    seq_pad = sequence.pad_sequences(seq_, maxlen = max_length_)\n",
    "    #clf_prediction = clf_.predict(seq_pad)\n",
    "    clf_prediction = model.predict_classes(seq_pad)\n",
    "    \n",
    "    #print(seq_)\n",
    "    #print(seq_pad)\n",
    "    \n",
    "    # Prediction to string\n",
    "    #clf_prediction_str = prediction_to_str(clf_prediction[0][0], category_id_)\n",
    "    clf_prediction = le.inverse_transform(clf_prediction)\n",
    "    \n",
    "    if(clf_prediction == ['Positive']):\n",
    "        return str(category_id_)\n",
    "    else:\n",
    "        return 'not ' + str(category_id_)\n",
    "    \n",
    "    \n",
    "def predict_proba(description_str, tok_, clf_, max_length_):\n",
    "    #seq_ = tok_.texts_to_sequences([description_str])\n",
    "    seq_ = texts_to_sequences_custom([description_str], tok_.word_index)\n",
    "    seq_pad = sequence.pad_sequences(seq_, maxlen = max_length_)\n",
    "    clf_prediction_proba = clf_.predict_proba(seq_pad, verbose=0)\n",
    "    \n",
    "    return clf_prediction_proba[0][0]\n",
    "\n",
    "\n",
    "# id_ = 'table Setr'\n",
    "# p = predict(id_, best_model_aux['Tokenizer'], best_model, best_model_aux['Max length'], best_model_aux['Category ID'])\n",
    "# pp = predict_proba(id_, best_model_aux['Tokenizer'], best_model, best_model_aux['Max length'])\n",
    "# print(p)\n",
    "# print(pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_file = \"nets_category_all_unigrams__traindata5000_vectrain5000_model.h5\"\n",
    "aux_file = \"nets_category_all_unigrams__traindata5000_vectrain5000_aux.pkl\"\n",
    "old_best_model_ = load_model(model_file)\n",
    "old_best_model_aux_ = get_model_file_aux(aux_file)\n",
    "old_tok_ = old_best_model_aux_['Tokenizer']\n",
    "old_word_index_ = old_best_model_aux_['Tokenizer'].word_index\n",
    "\n",
    "\n",
    "# item_d = \"tekton 2780 10slot screwdriver holder and organizer\"\n",
    "# print('Old model prediction:')\n",
    "# print('item:',item_d)\n",
    "# print('Seq max len:', old_best_model_aux_['Max length'])\n",
    "# print(predict(item_d, old_tok_, old_best_model_, old_best_model_aux_['Max length'], '927'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_ls = np.array(list(train_df['description_mod1']))\n",
    "seq_ = texts_to_sequences_custom(X_ls, old_word_index_)\n",
    "seq_pad = sequence.pad_sequences(seq_, maxlen = 30)\n",
    "predictions = old_best_model_.predict_classes(seq_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_mod1</th>\n",
       "      <th>category_id_mod1</th>\n",
       "      <th>category_full_path_mod1</th>\n",
       "      <th>target_le</th>\n",
       "      <th>Predictions</th>\n",
       "      <th>Predictions_le</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>it jeans maternity skinny jeans dark wash m</td>\n",
       "      <td>100</td>\n",
       "      <td>Apparel &amp; Accessories &gt; Apparel &gt; Maternity</td>\n",
       "      <td>28</td>\n",
       "      <td>Apparel &amp; Accessories &gt; Apparel &gt; Maternity</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1822 denim butter maternity skinny jeans rinse...</td>\n",
       "      <td>100</td>\n",
       "      <td>Apparel &amp; Accessories &gt; Apparel &gt; Maternity</td>\n",
       "      <td>28</td>\n",
       "      <td>Apparel &amp; Accessories &gt; Apparel &gt; Maternity</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25 j brand maternity skinny jean nirvana blue</td>\n",
       "      <td>100</td>\n",
       "      <td>Apparel &amp; Accessories &gt; Apparel &gt; Maternity</td>\n",
       "      <td>28</td>\n",
       "      <td>Apparel &amp; Accessories &gt; Apparel &gt; Maternity</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26 j brand maternity skinny jean nirvana blue</td>\n",
       "      <td>100</td>\n",
       "      <td>Apparel &amp; Accessories &gt; Apparel &gt; Maternity</td>\n",
       "      <td>28</td>\n",
       "      <td>Apparel &amp; Accessories &gt; Apparel &gt; Maternity</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26 james jeans maternity skinny external mater...</td>\n",
       "      <td>100</td>\n",
       "      <td>Apparel &amp; Accessories &gt; Apparel &gt; Maternity</td>\n",
       "      <td>28</td>\n",
       "      <td>Apparel &amp; Accessories &gt; Apparel &gt; Maternity</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    description_mod1  category_id_mod1  \\\n",
       "0        it jeans maternity skinny jeans dark wash m               100   \n",
       "1  1822 denim butter maternity skinny jeans rinse...               100   \n",
       "2      25 j brand maternity skinny jean nirvana blue               100   \n",
       "3      26 j brand maternity skinny jean nirvana blue               100   \n",
       "4  26 james jeans maternity skinny external mater...               100   \n",
       "\n",
       "                       category_full_path_mod1  target_le  \\\n",
       "0  Apparel & Accessories > Apparel > Maternity         28   \n",
       "1  Apparel & Accessories > Apparel > Maternity         28   \n",
       "2  Apparel & Accessories > Apparel > Maternity         28   \n",
       "3  Apparel & Accessories > Apparel > Maternity         28   \n",
       "4  Apparel & Accessories > Apparel > Maternity         28   \n",
       "\n",
       "                                   Predictions  Predictions_le  \n",
       "0  Apparel & Accessories > Apparel > Maternity              28  \n",
       "1  Apparel & Accessories > Apparel > Maternity              28  \n",
       "2  Apparel & Accessories > Apparel > Maternity              28  \n",
       "3  Apparel & Accessories > Apparel > Maternity              28  \n",
       "4  Apparel & Accessories > Apparel > Maternity              28  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Predictions_le'] = list(predictions)\n",
    "train_df['Predictions'] = train_df['Predictions_le'].apply(lambda x: le.inverse_transform(x))\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df.to_csv('truth_and_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ====================================================================================================\n",
      "Old model prediction:\n",
      "item: tekton 2655 flare nut wrench set metric 6piece\n",
      "Seq max len: 30\n",
      "not 927\n",
      "4.17323e-08\n",
      "\n",
      "Fresh model prediction:\n",
      "item: tekton 2655 flare nut wrench set metric 6piece\n",
      "Seq max len: 30\n",
      "1/1 [==============================] - 0s\n",
      "not 927\n",
      "\n",
      "1 ====================================================================================================\n",
      "Old model prediction:\n",
      "item: tekton 2780 10slot screwdriver holder and organizer\n",
      "Seq max len: 30\n",
      "not 927\n",
      "0.121584\n",
      "\n",
      "Fresh model prediction:\n",
      "item: tekton 2780 10slot screwdriver holder and organizer\n",
      "Seq max len: 30\n",
      "1/1 [==============================] - 0s\n",
      "927\n",
      "\n",
      "2 ====================================================================================================\n",
      "Old model prediction:\n",
      "item: titan 17237 insulated electrical screwdriver set  7 piece\n",
      "Seq max len: 30\n",
      "927\n",
      "0.998989\n",
      "\n",
      "Fresh model prediction:\n",
      "item: titan 17237 insulated electrical screwdriver set  7 piece\n",
      "Seq max len: 30\n",
      "1/1 [==============================] - 0s\n",
      "927\n",
      "\n",
      "3 ====================================================================================================\n",
      "Old model prediction:\n",
      "item: tool sorter screwdriver organizer red\n",
      "Seq max len: 30\n",
      "not 927\n",
      "0.405264\n",
      "\n",
      "Fresh model prediction:\n",
      "item: tool sorter screwdriver organizer red\n",
      "Seq max len: 30\n",
      "1/1 [==============================] - 0s\n",
      "927\n",
      "\n",
      "4 ====================================================================================================\n",
      "Old model prediction:\n",
      "item: torin sdh15rt magnetic screwdriver holder\n",
      "Seq max len: 30\n",
      "927\n",
      "0.994613\n",
      "\n",
      "Fresh model prediction:\n",
      "item: torin sdh15rt magnetic screwdriver holder\n",
      "Seq max len: 30\n",
      "1/1 [==============================] - 0s\n",
      "927\n",
      "\n",
      "5 ====================================================================================================\n",
      "Old model prediction:\n",
      "item: wera 05020013001 joker combination wrenchset 11 pieces\n",
      "Seq max len: 30\n",
      "not 927\n",
      "0.0210169\n",
      "\n",
      "Fresh model prediction:\n",
      "item: wera 05020013001 joker combination wrenchset 11 pieces\n",
      "Seq max len: 30\n",
      "1/1 [==============================] - 0s\n",
      "not 927\n",
      "\n",
      "6 ====================================================================================================\n",
      "Old model prediction:\n",
      "item: wera kk vde 60i62i68i18 insulated pouch set with interchangeable blades 18piece\n",
      "Seq max len: 30\n",
      "927\n",
      "0.995252\n",
      "\n",
      "Fresh model prediction:\n",
      "item: wera kk vde 60i62i68i18 insulated pouch set with interchangeable blades 18piece\n",
      "Seq max len: 30\n",
      "1/1 [==============================] - 0s\n",
      "927\n",
      "\n",
      "7 ====================================================================================================\n",
      "Old model prediction:\n",
      "item: wiha 28103 magnetic 14 bit holder stubby 57mm pliers screwdriver\n",
      "Seq max len: 30\n",
      "927\n",
      "0.972863\n",
      "\n",
      "Fresh model prediction:\n",
      "item: wiha 28103 magnetic 14 bit holder stubby 57mm pliers screwdriver\n",
      "Seq max len: 30\n",
      "1/1 [==============================] - 0s\n",
      "927\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TEST\n",
    "\n",
    "## load old model\n",
    "model_file = \"category_927_nets__traindata5000_vectrain5000_model.h5\"\n",
    "aux_file = \"category_927_nets__traindata5000_vectrain5000_aux.pkl\"\n",
    "old_best_model_ = load_model(model_file)\n",
    "old_best_model_aux_ = get_model_file_aux(aux_file)\n",
    "old_tok_ = old_best_model_aux_['Tokenizer']\n",
    "old_word_index_ = old_best_model_aux_['Tokenizer'].word_index\n",
    "\n",
    "## use fresh model\n",
    "best_model_ = best_model\n",
    "best_model_aux_ = best_model_aux\n",
    "tok_ = tok\n",
    "word_index_ = word_index\n",
    "\n",
    "item_d = 'NieR: Automata™ DEMO 120161128 (Playable Demo)'\n",
    "\n",
    "# screwdrivers check\n",
    "scrw_items = [\n",
    "\"tekton 2655 flare nut wrench set metric 6piece\"\n",
    ",\"tekton 2780 10slot screwdriver holder and organizer\"\n",
    ",\"titan 17237 insulated electrical screwdriver set  7 piece\"\n",
    ",\"tool sorter screwdriver organizer red\"\n",
    ",\"torin sdh15rt magnetic screwdriver holder\"  #wrong predict\n",
    ",\"wera 05020013001 joker combination wrenchset 11 pieces\"\n",
    ",\"wera kk vde 60i62i68i18 insulated pouch set with interchangeable blades 18piece\" # tricky\n",
    ",\"wiha 28103 magnetic 14 bit holder stubby 57mm pliers screwdriver\" # tricky, wrong predict\n",
    "]\n",
    "\n",
    "for n, i in enumerate(scrw_items):\n",
    "    item_d = i\n",
    "    \n",
    "    print(str(n) + ' ' + '='*100)\n",
    "    \n",
    "    print('Old model prediction:')\n",
    "    print('item:',item_d)\n",
    "    print('Seq max len:', old_best_model_aux_['Max length'])\n",
    "    print(predict(item_d, old_tok_, old_best_model_, old_best_model_aux_['Max length'], '927'))\n",
    "    print(predict_proba(item_d, old_tok_, old_best_model_, old_best_model_aux_['Max length']))\n",
    "\n",
    "\n",
    "    print('\\nFresh model prediction:')\n",
    "    print('item:',item_d)\n",
    "    print('Seq max len:', best_model_aux_['Max length'])\n",
    "    print(predict_2(item_d, tok_, best_model_, best_model_aux_['Max length'], '927'))\n",
    "    #print(predict_proba(item_d, tok_, best_model_, best_model_aux_['Max length']))\n",
    "\n",
    "    print()\n",
    "\n",
    "    #tt = train_df.loc[0:10,['description_mod1']]\n",
    "    #tt['pred'] = tt['description_mod1'].apply(lambda x: predict(x, best_model_aux_['Tokenizer'], best_model, best_model_aux_['Max length'], best_model_aux_['Category ID']))\n",
    "    #tt['prob'] = tt['description_mod1'].apply(lambda x: predict_proba(x, best_model_aux_['Tokenizer'], best_model, best_model_aux_['Max length']))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
