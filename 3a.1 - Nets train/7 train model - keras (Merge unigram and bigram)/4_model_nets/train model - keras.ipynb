{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Keras \n",
    "# Classifier: Merged unigram LSTM and bigram LSTM\n",
    "# Classification type: multi-class (404 classes)\n",
    "# Output nodes: #of classes with softmax\n",
    "\n",
    "# word2vec model: \n",
    "# word2vect_class_specififc_bigrams__vec64_win1__dict_sample_5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing process_string.py \n",
      "from /Users/altay.amanbay/Desktop/new node booster/experiments/3a.1 - Nets train/7 train model - keras (Merge unigram and bigram)/2_common_aux_script ...\n",
      "\n",
      "3.5.2 |Anaconda 4.2.0 (x86_64)| (default, Jul  2 2016, 17:52:12) \n",
      "[GCC 4.2.1 Compatible Apple LLVM 4.2 (clang-425.0.28)]\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "import theano\n",
    "theano.config.device = 'gpu'\n",
    "theano.config.floatX = 'float32'\n",
    "\n",
    "from keras.datasets import reuters\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.models import load_model, Sequential\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Dense, Dropout, Activation, LSTM, Bidirectional, Merge\n",
    "from keras.layers import Convolution1D, MaxPooling1D, Flatten\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.text import Tokenizer, one_hot, text_to_word_sequence\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "from keras.utils.visualize_util import plot\n",
    "from IPython.display import SVG\n",
    "from keras.utils.visualize_util import model_to_dot\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# import custom code\n",
    "import os\n",
    "import sys\n",
    "pardir = os.path.abspath(os.path.join(os.getcwd(), '../'))\n",
    "script_path = pardir + \"/2_common_aux_script\"\n",
    "print('Importing process_string.py \\nfrom ' + script_path + \" ...\\n\")\n",
    "sys.path.append(script_path)\n",
    "from process_string import process_string\n",
    "sys.path.remove(script_path)\n",
    "\n",
    "\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Functions\n",
    "\n",
    "def NGramGenerator_wordwise_interval(phrase, min_ngram, max_ngram):\n",
    "    all_ngram_lists = []\n",
    "\n",
    "    #printable_ = 'abcdefghijklmnopqrstuvwxyz0123456789 '\n",
    "    #s_split = \"\".join((char if char in printable_ else \"\") for char in phrase).split()\n",
    "    #phrase_processed = process_string(phrase)\n",
    "    #s_split = phrase_processed.split()\n",
    "    s_split = phrase.split()\n",
    "    \n",
    "    for n in range(max_ngram, min_ngram - 1, -1):\n",
    "        n_gram = [s_split[i:i+n] for i in range(len(s_split)-n+1)]\n",
    "        all_ngram_lists.extend(n_gram)\n",
    "        \n",
    "    all_ngrams = []\n",
    "    for n_gram in all_ngram_lists:\n",
    "        all_ngrams.extend([' '.join(n_gram)])\n",
    "    \n",
    "    return all_ngrams\n",
    "\n",
    "def get_word2index(texts_ls_):\n",
    "    word2index_ = {}\n",
    "\n",
    "    c = 1\n",
    "    for text_str in texts_ls_:\n",
    "        text_tokens_ls = text_str.lower().split()\n",
    "        for token in text_tokens_ls:\n",
    "            if(token not in word2index_):\n",
    "                word2index_[token] = c\n",
    "                c = c + 1\n",
    "                \n",
    "    return word2index_\n",
    "\n",
    "def train_df_preprocess(top_words_, texts_ls_, max_pad_length_):\n",
    "    # texts_ls_: list of texts strings\n",
    "    \n",
    "    tok = Tokenizer(top_words_)\n",
    "    tok.fit_on_texts(texts_ls_)\n",
    "\n",
    "    words = []\n",
    "    for iter in range(top_words):\n",
    "        words += [key for key,value in tok.word_index.items() if value==iter+1]\n",
    "\n",
    "    #Class for vectorizing texts, or/and turning texts into sequences \n",
    "    #(=list of word indexes, where the word of rank i in the dataset (starting at 1) has index i).\n",
    "    texts_vec_ls = tok.texts_to_sequences(texts_ls_)#turns text to sequence, stating which word comes in what place\n",
    "    texts_vec_mtx = sequence.pad_sequences(texts_vec_ls, maxlen=max_pad_length_)#pad sequence, essentially padding it with 0's at the end\n",
    "    \n",
    "    return texts_vec_mtx\n",
    "\n",
    "def text_2_vec(text_str, word2index_):\n",
    "    # text_str: text string\n",
    "    \n",
    "    text_tokens_ls = text_str.lower().split()\n",
    "    \n",
    "    text_vec = []\n",
    "    for token in text_tokens_ls:\n",
    "        if token in word2index_:\n",
    "            text_vec.append(word2index_[token])\n",
    "        else:\n",
    "            text_vec.append(0)\n",
    "            \n",
    "    return text_vec\n",
    "\n",
    "def train_df_preprocess_2(texts_ls_, word2index_, max_pad_length_):\n",
    "    # texts_ls_: list of texts strings\n",
    "    \n",
    "    texts_vec_ls = []\n",
    "    for text_ in texts_ls_:\n",
    "        #print(text_)\n",
    "        #print(type(text_))\n",
    "        text_vec = text_2_vec(text_, word2index_)\n",
    "        texts_vec_ls.append(text_vec)\n",
    "    \n",
    "    texts_vec_ary = sequence.pad_sequences(texts_vec_ls, maxlen=max_pad_length_)\n",
    "    \n",
    "    return texts_vec_ary\n",
    "\n",
    "def texts_to_sequences_custom(texts_ls, word_index_):\n",
    "    texts_seq = []\n",
    "    \n",
    "    for text in texts_ls:\n",
    "        #text_split = text.lower().split()\n",
    "        text_split = NGramGenerator_wordwise_interval(text,1,1)\n",
    "        seq = []\n",
    "        for token in text_split:\n",
    "            if(token in word_index_):\n",
    "                seq.append(word_index_[token])\n",
    "            else:\n",
    "                seq.append(0)\n",
    "                \n",
    "        texts_seq.append(seq)\n",
    "#         for k,v in word_index_.items():\n",
    "#             if(v == 395):\n",
    "#                 print(k,v)\n",
    "    return texts_seq\n",
    "\n",
    "\n",
    "def get_model_file_aux(model_file_aux_name):\n",
    "    with open(model_file_aux_name, 'rb') as pickle_file:\n",
    "        model_file_aux = pickle.load(pickle_file)\n",
    "    return model_file_aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aa_bb bb_cc cc_df'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def BiGramize(phrase_):\n",
    "    s = []\n",
    "    phrase_processed = process_string(phrase_)\n",
    "    for t in NGramGenerator_wordwise_interval(phrase_processed, 2, 2):\n",
    "        s.append(t.replace(' ','_'))\n",
    "\n",
    "    return ' '.join(s)\n",
    "\n",
    "BiGramize('AA bb c@c Df!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples data shape: (956776, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_mod1</th>\n",
       "      <th>category_id_mod1</th>\n",
       "      <th>category_full_path_mod1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>!iT Jeans Maternity Skinny Jeans Dark Wash M</td>\n",
       "      <td>100</td>\n",
       "      <td>Apparel &amp; Accessories &gt; Apparel &gt; Maternity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1822 Denim 'Butter' Maternity Skinny Jeans Rin...</td>\n",
       "      <td>100</td>\n",
       "      <td>Apparel &amp; Accessories &gt; Apparel &gt; Maternity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25 J Brand Maternity Skinny Jean nirvana blue</td>\n",
       "      <td>100</td>\n",
       "      <td>Apparel &amp; Accessories &gt; Apparel &gt; Maternity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26 J Brand Maternity Skinny Jean nirvana blue</td>\n",
       "      <td>100</td>\n",
       "      <td>Apparel &amp; Accessories &gt; Apparel &gt; Maternity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26 James Jeans Maternity Skinny External Mater...</td>\n",
       "      <td>100</td>\n",
       "      <td>Apparel &amp; Accessories &gt; Apparel &gt; Maternity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    description_mod1  category_id_mod1  \\\n",
       "0       !iT Jeans Maternity Skinny Jeans Dark Wash M               100   \n",
       "1  1822 Denim 'Butter' Maternity Skinny Jeans Rin...               100   \n",
       "2      25 J Brand Maternity Skinny Jean nirvana blue               100   \n",
       "3      26 J Brand Maternity Skinny Jean nirvana blue               100   \n",
       "4  26 James Jeans Maternity Skinny External Mater...               100   \n",
       "\n",
       "                       category_full_path_mod1  \n",
       "0  Apparel & Accessories > Apparel > Maternity  \n",
       "1  Apparel & Accessories > Apparel > Maternity  \n",
       "2  Apparel & Accessories > Apparel > Maternity  \n",
       "3  Apparel & Accessories > Apparel > Maternity  \n",
       "4  Apparel & Accessories > Apparel > Maternity  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read sampled descriptionary\n",
    "\n",
    "path = pardir+'/1_data/'\n",
    "file_name = 'sampled_descriptionary_sample_size_5000.csv'\n",
    "samples_df = pd.read_csv(path + file_name)\n",
    "\n",
    "# Rename columns\n",
    "samples_df.rename(columns={'description': 'description_mod1', \n",
    "                           'category_id': 'category_id_mod1',\n",
    "                           'category_path': 'category_full_path_mod1'}, inplace=True)\n",
    "\n",
    "# Drop 'screwdrivers' from descriptionary\n",
    "#samples_df = samples_df.loc[samples_df.category_id_mod1 != 927,:]\n",
    "\n",
    "# Drop index column\n",
    "samples_df.drop(labels=['index'], axis=1, inplace=True)\n",
    "\n",
    "print('samples data shape:',samples_df.shape)\n",
    "samples_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data shape (original): (956776, 5)\n",
      "train data shape (deduplicated): (938810, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_mod1</th>\n",
       "      <th>category_id_mod1</th>\n",
       "      <th>category_full_path_mod1</th>\n",
       "      <th>unigrams</th>\n",
       "      <th>bigrams</th>\n",
       "      <th>target_le</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>!iT Jeans Maternity Skinny Jeans Dark Wash M</td>\n",
       "      <td>100</td>\n",
       "      <td>Apparel &amp; Accessories &gt; Apparel &gt; Maternity</td>\n",
       "      <td>it jeans maternity skinny jeans dark wash m</td>\n",
       "      <td>it_jeans jeans_maternity maternity_skinny skin...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1822 Denim 'Butter' Maternity Skinny Jeans Rin...</td>\n",
       "      <td>100</td>\n",
       "      <td>Apparel &amp; Accessories &gt; Apparel &gt; Maternity</td>\n",
       "      <td>1822 denim butter maternity skinny jeans rinse...</td>\n",
       "      <td>1822_denim denim_butter butter_maternity mater...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    description_mod1  category_id_mod1  \\\n",
       "0       !iT Jeans Maternity Skinny Jeans Dark Wash M               100   \n",
       "1  1822 Denim 'Butter' Maternity Skinny Jeans Rin...               100   \n",
       "\n",
       "                       category_full_path_mod1  \\\n",
       "0  Apparel & Accessories > Apparel > Maternity   \n",
       "1  Apparel & Accessories > Apparel > Maternity   \n",
       "\n",
       "                                            unigrams  \\\n",
       "0        it jeans maternity skinny jeans dark wash m   \n",
       "1  1822 denim butter maternity skinny jeans rinse...   \n",
       "\n",
       "                                             bigrams  target_le  \n",
       "0  it_jeans jeans_maternity maternity_skinny skin...         27  \n",
       "1  1822_denim denim_butter butter_maternity mater...         27  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concat original train set and sampled descriptionary\n",
    "#train_df = pd.concat([train_df, samples_df], axis=0)\n",
    "train_df = samples_df\n",
    "#train_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# description into chars\n",
    "train_df['unigrams'] = train_df['description_mod1'].apply(lambda x: process_string(x))\n",
    "train_df['bigrams']  = train_df['description_mod1'].apply(lambda x: BiGramize(x))\n",
    "print('train data shape (original):',train_df.shape)\n",
    "\n",
    "# deduplicate\n",
    "train_df.drop_duplicates(subset=['unigrams'], inplace = True, keep=False)\n",
    "print('train data shape (deduplicated):',train_df.shape)\n",
    "    \n",
    "# Encode target feature\n",
    "le = LabelEncoder()\n",
    "le.fit(train_df['category_full_path_mod1'])\n",
    "train_df['target_le'] = le.transform(train_df['category_full_path_mod1'])\n",
    "\n",
    "\n",
    "train_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "938810\n",
      "(938810, 398)\n",
      "word_index size: 234950\n",
      "train_texts_vec_mtx_unigrams shape: (938810, 30)\n"
     ]
    }
   ],
   "source": [
    "# Process for unigrams\n",
    "# Create train set from whole data set\n",
    "# and create padded sequences\n",
    "X_ls = np.array(list(train_df['unigrams']))\n",
    "y_ary = np.array(list(train_df['target_le']))\n",
    "y_ary_cat = np_utils.to_categorical(train_df['target_le'])\n",
    "\n",
    "print(type(X_ls))\n",
    "print(type(y_ary_cat))\n",
    "\n",
    "#X_train_ls, X_test_ls, y_train_ary, y_test_ary = train_test_split(X_ls, y_ary_cat, test_size = 0.3)\n",
    "\n",
    "print(len(X_ls))\n",
    "print(y_ary_cat.shape)\n",
    "\n",
    "# Convert train set into sequences for nets\n",
    "top_words = None  # None: all words\n",
    "max_description_length = 30\n",
    "\n",
    "tok = Tokenizer(nb_words = top_words, filters='.')  # set filters randomly to dot, else it will remove underscores\n",
    "tok.fit_on_texts(X_ls)\n",
    "word_index_unigrams = tok.word_index\n",
    "print('word_index size:',len(word_index_unigrams))\n",
    "\n",
    "#train_texts_vec_ls = tok.texts_to_sequences(X_train_ls)\n",
    "train_texts_vec_ls_unigrams = texts_to_sequences_custom(X_ls, word_index_unigrams)\n",
    "train_texts_vec_mtx_unigrams = sequence.pad_sequences(train_texts_vec_ls_unigrams, maxlen = max_description_length)\n",
    "\n",
    "print('train_texts_vec_mtx_unigrams shape:',train_texts_vec_mtx_unigrams.shape)\n",
    "list(word_index_unigrams)[0:5]\n",
    "\n",
    "# Delete objects\n",
    "X_ls = None\n",
    "y_ary = None\n",
    "tok = None\n",
    "train_texts_vec_ls_unigrams = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "938810\n",
      "word_index size: 1719079\n",
      "train_texts_vec_mtx_unigrams shape: (938810, 30)\n"
     ]
    }
   ],
   "source": [
    "# Process for bigrams\n",
    "# Create train set from whole data set\n",
    "# and create padded sequences\n",
    "X_ls = np.array(list(train_df['bigrams']))\n",
    "\n",
    "print(type(X_ls))\n",
    "print(len(X_ls))\n",
    "\n",
    "# Convert train set into sequences for nets\n",
    "top_words = None  # None: all words\n",
    "max_description_length = 30\n",
    "\n",
    "tok = Tokenizer(nb_words = top_words, filters='.')  # set filters randomly to dot, else it will remove underscores\n",
    "tok.fit_on_texts(X_ls)\n",
    "word_index_bigrams = tok.word_index\n",
    "print('word_index size:',len(word_index_bigrams))\n",
    "\n",
    "train_texts_vec_ls_bigrams = texts_to_sequences_custom(X_ls, word_index_bigrams)\n",
    "train_texts_vec_mtx_bigrams = sequence.pad_sequences(train_texts_vec_ls_bigrams, maxlen = max_description_length)\n",
    "\n",
    "print('train_texts_vec_mtx_unigrams shape:',train_texts_vec_mtx_unigrams.shape)\n",
    "list(word_index_bigrams)[0:5]\n",
    "\n",
    "# Delete objects\n",
    "X_ls = None\n",
    "tok = None\n",
    "train_texts_vec_ls_bigrams = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mtx_unigrams [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0 6813 4236  251   68   34 2297   49 2297  267]\n",
      "Mtx_bigrams [      0       0       0       0       0       0       0       0       0\n",
      "       0       0       0       0       0       0       0       0       0\n",
      "       0       0       0       0   20244  445544     819      19  491051\n",
      " 1183050 1683820 1709986] \n",
      "\n",
      "word_index_unigrams 234950\n",
      "word_index_bigrams 1719079\n"
     ]
    }
   ],
   "source": [
    "# test check\n",
    "i = 101\n",
    "#print('Vec_unigrams',train_texts_vec_ls_unigrams[i])\n",
    "print('Mtx_unigrams',train_texts_vec_mtx_unigrams[i])\n",
    "#print('Vec_bigrams',train_texts_vec_ls_bigrams[i])\n",
    "print('Mtx_bigrams',train_texts_vec_mtx_bigrams[i],'\\n')\n",
    "\n",
    "print('word_index_unigrams',len(word_index_unigrams))\n",
    "print('word_index_bigrams',len(word_index_bigrams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/altay.amanbay/Desktop/new node booster/experiments/3a.1 - Nets train/7 train model - keras (Merge unigram and bigram)/3_model_word2vec/word2vect_class_specififc_unigrams__vec64_win1__dict_sample_5000\n",
      "Loaded 235761 word vectors.\n",
      "embedding_vecor_length: 64\n",
      "\n",
      "embedding matrix shape: (234951, 64)\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[-0.06146404  0.081076    0.00112323  0.04499147  0.1002018   0.01332603\n",
      " -0.19582143 -0.03727768  0.08618295 -0.24972945 -0.06021989  0.28060985\n",
      "  0.08473843  0.04667721  0.13200024 -0.15039206  0.00561094 -0.21778092\n",
      " -0.09161391  0.0259797  -0.11244918 -0.01754784 -0.08015888 -0.11885061\n",
      "  0.13581887 -0.08760685  0.05284847  0.12670977 -0.05489041  0.32682282\n",
      " -0.00553122 -0.03708532 -0.05104759  0.01759537  0.11875682  0.13249238\n",
      " -0.05064112  0.17661691  0.03251493  0.02025766  0.11108632 -0.05402073\n",
      " -0.13319896  0.0944826  -0.00662499  0.20068783  0.07138328 -0.17812581\n",
      "  0.06006688  0.06778252 -0.17951348 -0.00747066  0.01565725  0.00944159\n",
      "  0.1358608   0.18168604  0.2046535  -0.28609699  0.07989392  0.14673866\n",
      " -0.14850725  0.10774294 -0.10994995  0.10638081]\n"
     ]
    }
   ],
   "source": [
    "## Create word embeddings from trained Word2Vec model\n",
    "## for unigrams\n",
    "from gensim.models import word2vec, Phrases\n",
    "\n",
    "# Load model\n",
    "file_path_1 = pardir+\"/3_model_word2vec/word2vect_class_specififc_unigrams__vec64_win1__dict_sample_5000\"\n",
    "print(file_path_1)\n",
    "model = word2vec.Word2Vec.load(file_path_1)\n",
    "\n",
    "#print(model.vocab.keys())\n",
    "#sys.exit()\n",
    "\n",
    "# word vector embeddings from model into dictionary\n",
    "word2vec_dict={}\n",
    "for word in model.vocab.keys():\n",
    "    try:\n",
    "        word2vec_dict[word]=model[word]\n",
    "    except:    \n",
    "        pass\n",
    "print('Loaded %s word vectors.' % len(word2vec_dict))\n",
    "    \n",
    "embedding_vecor_length = len(model[word])\n",
    "print('embedding_vecor_length:',embedding_vecor_length)\n",
    "\n",
    "\n",
    "embedding_matrix_unigrams = np.zeros((len(word_index_unigrams) + 1, embedding_vecor_length))\n",
    "for word, i in word_index_unigrams.items():\n",
    "    embedding_vector = word2vec_dict.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix_unigrams[i] = embedding_vector\n",
    "        \n",
    "print('\\nembedding matrix shape:',embedding_matrix_unigrams.shape)\n",
    "print(embedding_matrix_unigrams[0]) # first cell should be all zeros\n",
    "print(embedding_matrix_unigrams[1])\n",
    "\n",
    "# Delete objects\n",
    "model = None\n",
    "word2vec_dict = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/altay.amanbay/Desktop/new node booster/experiments/3a.1 - Nets train/7 train model - keras (Merge unigram and bigram)/3_model_word2vec/word2vect_class_specififc_bigrams__vec64_win1__dict_sample_5000\n",
      "Loaded 1723576 word vectors.\n",
      "embedding_vecor_length: 64\n",
      "\n",
      "embedding matrix shape: (1719080, 64)\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.00602353 -0.12864356 -0.11898886  0.19484989  0.09767632 -0.0804306\n",
      " -0.05070817 -0.09657203  0.13073626  0.1669164  -0.04072534 -0.09930911\n",
      "  0.00819166  0.21398458 -0.14614362 -0.15424693  0.01904099  0.00494983\n",
      " -0.20303769  0.08396353  0.09175193  0.01089812 -0.05856525  0.13049573\n",
      "  0.12205232 -0.11231349  0.16520451  0.15166625  0.0934044   0.05492248\n",
      "  0.09600082  0.10321151  0.00243238  0.13833098 -0.05925417  0.08356452\n",
      "  0.13621683  0.29268152 -0.01313289 -0.23804311 -0.10872968 -0.1286303\n",
      " -0.08047052 -0.12728453 -0.10570092  0.11440181  0.07822752  0.23402858\n",
      "  0.16372128  0.11063954 -0.06513771 -0.1041393   0.04630629  0.02327882\n",
      "  0.18996462  0.1121234  -0.08975061  0.0487235   0.07489642  0.23314126\n",
      " -0.0793527   0.19243822 -0.11999152  0.09135503]\n"
     ]
    }
   ],
   "source": [
    "## Create word embeddings from trained Word2Vec model\n",
    "## for bigrams\n",
    "from gensim.models import word2vec, Phrases\n",
    "\n",
    "# Load model\n",
    "file_path_1 = pardir+\"/3_model_word2vec/word2vect_class_specififc_bigrams__vec64_win1__dict_sample_5000\"\n",
    "print(file_path_1)\n",
    "model = word2vec.Word2Vec.load(file_path_1)\n",
    "\n",
    "#print(model.vocab.keys())\n",
    "#sys.exit()\n",
    "\n",
    "# word vector embeddings from model into dictionary\n",
    "word2vec_dict={}\n",
    "for word in model.vocab.keys():\n",
    "    try:\n",
    "        word2vec_dict[word]=model[word]\n",
    "    except:    \n",
    "        pass\n",
    "print('Loaded %s word vectors.' % len(word2vec_dict))\n",
    "    \n",
    "embedding_vecor_length = len(model[word])\n",
    "print('embedding_vecor_length:',embedding_vecor_length)\n",
    "\n",
    "\n",
    "embedding_matrix_bigrams = np.zeros((len(word_index_bigrams) + 1, embedding_vecor_length))\n",
    "for word, i in word_index_bigrams.items():\n",
    "    embedding_vector = word2vec_dict.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix_bigrams[i] = embedding_vector\n",
    "        \n",
    "print('\\nembedding matrix shape:',embedding_matrix_bigrams.shape)\n",
    "print(embedding_matrix_bigrams[0]) # first cell should be all zeros\n",
    "print(embedding_matrix_bigrams[1])\n",
    "\n",
    "# Delete objects\n",
    "model = None\n",
    "word2vec_dict = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Best model result holder\n",
    "best_model_aux = {}\n",
    "best_model_aux['Best score'] = 0\n",
    "best_model_aux['Max length'] = max_description_length\n",
    "best_model_aux['texts_to_sequences'] = texts_to_sequences_custom\n",
    "best_model_aux['word_index_unigrams'] = word_index_unigrams\n",
    "best_model_aux['word_index_bigrams'] = word_index_bigrams\n",
    "best_model_aux['Label encoder'] = le\n",
    "\n",
    "best_model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Optional\n",
    "# Load previous model (if needs to be compared in the following training)\n",
    "#best_model = load_model('category_927_nets_1000_model.h5')\n",
    "#best_model_aux = get_model_file_aux('category_927_nets_1000_model_aux.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes count: 398\n"
     ]
    }
   ],
   "source": [
    "# prediction nodes count\n",
    "nb_classes = train_df['category_full_path_mod1'].unique()\n",
    "print('Classes count:', len(nb_classes))\n",
    "\n",
    "train_df = None\n",
    "samples_df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_layer_unigrams = None\n",
    "embedding_layer_bigrams = None\n",
    "model_1_lstm = None\n",
    "model_2_lstm = None\n",
    "model_merge = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_1 (Embedding)          (None, 30, 64)        15036864                                     \n",
      "____________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                    (None, 30, 128)       98816                                        \n",
      "____________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)          (None, 30, 64)        110021120                                    \n",
      "____________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                    (None, 128)           197120      merge_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 398)           51342       lstm_3[0][0]                     \n",
      "====================================================================================================\n",
      "Total params: 125,405,262\n",
      "Trainable params: 347,278\n",
      "Non-trainable params: 125,057,984\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "Epoch iter #1\n",
      "Epoch 1/1\n",
      "938810/938810 [==============================] - 3701s - loss: 0.3515 - acc: 0.9180  \n",
      "Captured improved model\n",
      "Valid accuracy:  0.970184595392\n",
      "\n",
      "Epoch iter #2\n",
      "Epoch 1/1\n",
      "938810/938810 [==============================] - 3636s - loss: 0.0950 - acc: 0.9704  \n",
      "Captured improved model\n",
      "Valid accuracy:  0.97304672937\n",
      "\n",
      "Epoch iter #3\n",
      "Epoch 1/1\n",
      "938810/938810 [==============================] - 3578s - loss: 0.0830 - acc: 0.9737  \n",
      "Captured improved model\n",
      "Valid accuracy:  0.977125296918\n",
      "\n",
      "Epoch iter #4\n",
      "Epoch 1/1\n",
      "938810/938810 [==============================] - 3585s - loss: 0.0657 - acc: 0.9785  \n",
      "Captured improved model\n",
      "Valid accuracy:  0.979699832767\n",
      "\n",
      "Epoch iter #5\n",
      "Epoch 1/1\n",
      "938810/938810 [==============================] - 3803s - loss: 0.0560 - acc: 0.9813  \n",
      "Captured improved model\n",
      "Valid accuracy:  0.984946900864\n",
      "\n",
      "Epoch iter #6\n",
      "Epoch 1/1\n",
      "938810/938810 [==============================] - 3694s - loss: 0.0497 - acc: 0.9832  \n",
      "Captured improved model\n",
      "Valid accuracy:  0.985580681927\n",
      "\n",
      "Epoch iter #7\n",
      "Epoch 1/1\n",
      "938810/938810 [==============================] - 3595s - loss: 0.0476 - acc: 0.9839  \n",
      "Captured improved model\n",
      "Valid accuracy:  0.986345479916\n",
      "\n",
      "Epoch iter #8\n",
      "Epoch 1/1\n",
      "938810/938810 [==============================] - 3986s - loss: 0.0445 - acc: 0.9849  \n",
      "Captured improved model\n",
      "Valid accuracy:  0.987594934012\n",
      "\n",
      "Epoch iter #9\n",
      "Epoch 1/1\n",
      "938810/938810 [==============================] - 3842s - loss: 0.0397 - acc: 0.9861  \n",
      "Captured improved model\n",
      "Valid accuracy:  0.988732544391\n",
      "\n",
      "Epoch iter #10\n",
      "Epoch 1/1\n",
      "938810/938810 [==============================] - 3579s - loss: 0.0364 - acc: 0.9871  \n",
      "Captured improved model\n",
      "Valid accuracy:  0.989302414759\n",
      "\n",
      "Epoch iter #11\n",
      "Epoch 1/1\n",
      "938810/938810 [==============================] - 3575s - loss: 0.0477 - acc: 0.9840  \n",
      "Training took 54240.1 s\n"
     ]
    }
   ],
   "source": [
    "# TRAIN MODEL 1\n",
    "start = time.time()\n",
    "\n",
    "# define/initialize model\n",
    "top_words_unigrams = len(word_index_unigrams) + 1\n",
    "top_words_bigrams = len(word_index_bigrams) + 1\n",
    "batch_size_ = 64   # 64\n",
    "\n",
    "## Model 1 (LSTM)\n",
    "## ======================================================================================\n",
    "model_1_lstm = Sequential()\n",
    "## Embedding layer\n",
    "embedding_layer_unigrams = Embedding(top_words_unigrams, \n",
    "                            embedding_vecor_length, \n",
    "                            weights=[embedding_matrix_unigrams], \n",
    "                            input_length = max_description_length,\n",
    "                            trainable=False)\n",
    "model_1_lstm.add(embedding_layer_unigrams)\n",
    "\n",
    "## LSTM 1\n",
    "LSTM_1 = LSTM(128,return_sequences=True)\n",
    "model_1_lstm.add(LSTM_1)\n",
    "\n",
    "\n",
    "## Model 2 (LSTM)\n",
    "## ======================================================================================\n",
    "model_2_lstm = Sequential()\n",
    "## Embedding layer\n",
    "embedding_layer_bigrams = Embedding(top_words_bigrams, \n",
    "                            embedding_vecor_length, \n",
    "                            weights=[embedding_matrix_bigrams], \n",
    "                            input_length = max_description_length,\n",
    "                            trainable=False)\n",
    "model_2_lstm.add(embedding_layer_bigrams)\n",
    "## LSTM 1\n",
    "LSTM_2 = LSTM(128,return_sequences=True)\n",
    "model_2_lstm.add(LSTM_1)\n",
    "\n",
    "\n",
    "## Merge models\n",
    "## ======================================================================================\n",
    "model_merge = Sequential()\n",
    "merge_layer = Merge([model_1_lstm,model_2_lstm], mode='concat')\n",
    "model_merge.add(merge_layer)\n",
    "model_merge.add(LSTM(128,return_sequences=False))\n",
    "\n",
    "\n",
    "## Output classes layer\n",
    "## ======================================================================================\n",
    "model_merge.add(Dense(len(nb_classes), activation='softmax'))\n",
    "model_merge.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])  # try loss=categorical_crossentropy\n",
    "print(model_merge.summary())\n",
    "\n",
    "# start training multiple times with epoch=1\n",
    "for ep in range(20):\n",
    "    print('Epoch iter #' + str(ep+1))\n",
    "    model_merge.fit([train_texts_vec_mtx_unigrams,train_texts_vec_mtx_bigrams], y_ary_cat, nb_epoch=1, batch_size=batch_size_)\n",
    "    \n",
    "    scores = model_merge.evaluate([train_texts_vec_mtx_unigrams,train_texts_vec_mtx_bigrams], y_ary_cat, verbose=0)\n",
    "    if(best_model_aux['Best score'] < scores[1]):\n",
    "        best_model_aux['Best score'] = scores[1]\n",
    "        best_model = model_merge\n",
    "        print('Captured improved model')\n",
    "        print('Valid accuracy: ',best_model_aux['Best score'])\n",
    "        #print(\"Accuracy on test set: %.2f%%\" % (scores[1]*100))\n",
    "    else:\n",
    "        break\n",
    "    print()\n",
    " \n",
    "\n",
    "print(\"Training took %g s\" % (time.time() - start))\n",
    "\n",
    "# Accuracy: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98930241475910996"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_aux['Best score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"264pt\" viewBox=\"0.00 0.00 332.25 264.00\" width=\"332pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 260)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-260 328.2451,-260 328.2451,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 6023254536 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>6023254536</title>\n",
       "<polygon fill=\"none\" points=\"0,-219.5 0,-255.5 153.2451,-255.5 153.2451,-219.5 0,-219.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"76.6226\" y=\"-233.3\">sequential_1: Sequential</text>\n",
       "</g>\n",
       "<!-- 5919087864 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>5919087864</title>\n",
       "<polygon fill=\"none\" points=\"107.415,-146.5 107.415,-182.5 215.8301,-182.5 215.8301,-146.5 107.415,-146.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"161.6226\" y=\"-160.3\">merge_1: Merge</text>\n",
       "</g>\n",
       "<!-- 6023254536&#45;&gt;5919087864 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>6023254536-&gt;5919087864</title>\n",
       "<path d=\"M97.6338,-219.4551C108.2589,-210.3299 121.3157,-199.1165 132.8581,-189.2036\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"135.2525,-191.7609 140.5584,-182.5904 130.6918,-186.4505 135.2525,-191.7609\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 6057873136 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>6057873136</title>\n",
       "<polygon fill=\"none\" points=\"171,-219.5 171,-255.5 324.2451,-255.5 324.2451,-219.5 171,-219.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"247.6226\" y=\"-233.3\">sequential_2: Sequential</text>\n",
       "</g>\n",
       "<!-- 6057873136&#45;&gt;5919087864 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>6057873136-&gt;5919087864</title>\n",
       "<path d=\"M226.3641,-219.4551C215.614,-210.3299 202.4036,-199.1165 190.7255,-189.2036\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"192.8233,-186.3934 182.9345,-182.5904 188.2933,-191.7301 192.8233,-186.3934\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 7656316432 -->\n",
       "<g class=\"node\" id=\"node4\">\n",
       "<title>7656316432</title>\n",
       "<polygon fill=\"none\" points=\"112.2002,-73.5 112.2002,-109.5 211.0449,-109.5 211.0449,-73.5 112.2002,-73.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"161.6226\" y=\"-87.3\">lstm_3: LSTM</text>\n",
       "</g>\n",
       "<!-- 5919087864&#45;&gt;7656316432 -->\n",
       "<g class=\"edge\" id=\"edge3\">\n",
       "<title>5919087864-&gt;7656316432</title>\n",
       "<path d=\"M161.6226,-146.4551C161.6226,-138.3828 161.6226,-128.6764 161.6226,-119.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"165.1227,-119.5903 161.6226,-109.5904 158.1227,-119.5904 165.1227,-119.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 7656315760 -->\n",
       "<g class=\"node\" id=\"node5\">\n",
       "<title>7656315760</title>\n",
       "<polygon fill=\"none\" points=\"109.4966,-.5 109.4966,-36.5 213.7485,-36.5 213.7485,-.5 109.4966,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"161.6226\" y=\"-14.3\">dense_1: Dense</text>\n",
       "</g>\n",
       "<!-- 7656316432&#45;&gt;7656315760 -->\n",
       "<g class=\"edge\" id=\"edge4\">\n",
       "<title>7656316432-&gt;7656315760</title>\n",
       "<path d=\"M161.6226,-73.4551C161.6226,-65.3828 161.6226,-55.6764 161.6226,-46.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"165.1227,-46.5903 161.6226,-36.5904 158.1227,-46.5904 165.1227,-46.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot Nets design\n",
    "#from keras.utils import plot_model\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils.visualize_util import model_to_dot\n",
    "\n",
    "#plot(model, to_file='/Users/altay.amanbay/Desktop/model.png')\n",
    "SVG(model_to_dot(model_merge).create(prog='dot', format='svg'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save model and aux file\n",
    "\n",
    "best_model.save('nets_category_all__traindata5000_vectrain5000_model.h5')\n",
    "\n",
    "best_model_aux_name = 'nets_category_all__traindata5000_vectrain5000_aux.pkl'\n",
    "with open(best_model_aux_name, 'wb') as pickle_file:\n",
    "    pickle.dump(best_model_aux, pickle_file, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set: 86.66%\n",
      "Accuracy on test set: 83.86%\n",
      "\n",
      "Evaluation took 390.131 s\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of the model\n",
    "start = time.time()\n",
    "\n",
    "scores = model.evaluate(train_texts_vec_mtx, y_train_ary, verbose=0)\n",
    "print(\"Accuracy on train set: %.2f%%\" % (scores[1]*100))\n",
    "scores = model.evaluate(test_texts_vec_mtx, y_test_ary, verbose=0)\n",
    "print(\"Accuracy on test set: %.2f%%\" % (scores[1]*100))\n",
    "\n",
    "print(\"\\nEvaluation took %g s\" % (time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions[0]       : 10\n",
      "\n",
      "Prediction took 0.000182152 s\n"
     ]
    }
   ],
   "source": [
    "# Get predictions\n",
    "start = time.time()\n",
    "\n",
    "predictions = model.predict_classes(test_texts_vec_mtx)\n",
    "#predictions_rnd = np.round_(predictions, decimals=0, out=None)\n",
    "predictions_probs = model.predict(test_texts_vec_mtx)\n",
    "\n",
    "print('%-20s' % \"predictions[0]\",':', predictions[0])\n",
    "#print('%-20s' % \"predictions_rnd[0]:\",':',predictions_rnd[0])\n",
    "#print('%-20s' % \"predictions_probs[0]\",':', predictions_probs[0])\n",
    "print(\"\\nPrediction took %g s\" % (time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tools & Home Improvement > Lighting, Light Bulbs & Ceiling Fans > Other\n",
      "[ 'progress lighting p299281 archiethree light bath vanity antique nickel finish'\n",
      " 'bulbrite 60a15f 60watt incandescent a15 appliance bulb frost'\n",
      " 'greenhouse indooroutdoor chandelier rasped iron finish' ...,\n",
      " 'ge advantage fluorescent'\n",
      " 'feit ctcdm500led 60w equivalent candelabra base torpedo tip chandelier led light soft white'\n",
      " 'alena 97 arched floor lamp by house of hampton'] \n",
      "\n",
      "Tools & Home Improvement > Lighting, Light Bulbs & Ceiling Fans > Light Fixtures & Lamps\n",
      "['cortina nightstand right door'\n",
      " 'camino vintage candelabra twotier chandelier 72'\n",
      " 'golden lighting 2501ba3' ..., 'aspect white 23 open unit'\n",
      " 'harpwell 7light oilrubbed bronze chandelier'\n",
      " 'connie 2light antique black flush mount'] \n",
      "\n",
      "Tools & Home Improvement > Lighting, Light Bulbs & Ceiling Fans > Light Bulbs\n",
      "[ '3 pack led light bulbs lohas b35 7w soft white 3000k e12 candelabra bulb equivalent to 6065 watt incandescent'\n",
      " 'br30 led bulbsluminwiz 9w 3000k 680lm soft white dimmable flood light bulb65w equivalentmedium base e26dimmableul listedenergy star pack of 4'\n",
      " 'philips 12watt 65w 420281 led br30 flood bright white 3000k light bulb'\n",
      " ...,\n",
      " '10 pack par38 led 13 watt 120w equivalent 3000k warm white dimmable indooroutdoor lighting 1050 lumens'\n",
      " '4watt 25w equivalent mr 16 gu 53 led bulb 249 lumens neutral bright 3500k  nondimmable'\n",
      " 'bulbrite industries r20 halogen reflector flood bulb'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Manual check which nodes are not distinguishable for nets\n",
    "class_ = 392\n",
    "print(le.inverse_transform(class_))\n",
    "print(X_test_ls[np_utils.categorical_probas_to_classes(y_test_ary)==class_],'\\n')\n",
    "\n",
    "class_ = 390\n",
    "print(le.inverse_transform(class_))\n",
    "print(X_test_ls[np_utils.categorical_probas_to_classes(y_test_ary)==class_],'\\n')\n",
    "\n",
    "class_ = 389\n",
    "print(le.inverse_transform(class_))\n",
    "print(X_test_ls[np_utils.categorical_probas_to_classes(y_test_ary)==class_],'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>...</th>\n",
       "      <th>389</th>\n",
       "      <th>390</th>\n",
       "      <th>392</th>\n",
       "      <th>393</th>\n",
       "      <th>394</th>\n",
       "      <th>395</th>\n",
       "      <th>396</th>\n",
       "      <th>397</th>\n",
       "      <th>403</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>1126</td>\n",
       "      <td>120</td>\n",
       "      <td>148</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>275</td>\n",
       "      <td>826</td>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>104</td>\n",
       "      <td>84</td>\n",
       "      <td>1242</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>304</td>\n",
       "      <td>49</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1320</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>202</td>\n",
       "      <td>405</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>136</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1353</td>\n",
       "      <td>26</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>45</td>\n",
       "      <td>947</td>\n",
       "      <td>326</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>394</td>\n",
       "      <td>270</td>\n",
       "      <td>759</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>488</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>844</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1391</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>1244</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>428</td>\n",
       "      <td>0</td>\n",
       "      <td>437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>147</td>\n",
       "      <td>17</td>\n",
       "      <td>1606</td>\n",
       "      <td>1061</td>\n",
       "      <td>1723</td>\n",
       "      <td>3</td>\n",
       "      <td>371</td>\n",
       "      <td>1642</td>\n",
       "      <td>480</td>\n",
       "      <td>145</td>\n",
       "      <td>...</td>\n",
       "      <td>1838</td>\n",
       "      <td>1384</td>\n",
       "      <td>1258</td>\n",
       "      <td>535</td>\n",
       "      <td>865</td>\n",
       "      <td>1456</td>\n",
       "      <td>1267</td>\n",
       "      <td>438</td>\n",
       "      <td>7</td>\n",
       "      <td>284293</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>363 rows × 323 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    1   2     3     4     5  6    9    10   11   12   ...     389  \\\n",
       "True                                                           ...           \n",
       "1          107   0    24     4     4  0    5     1    0    0   ...       0   \n",
       "2            7  12     0     0     6  0    0     0    0    0   ...       0   \n",
       "3           21   1  1126   120   148  0    0     8    0    0   ...       0   \n",
       "4            3   3   275   826   254  0    0    12    0    0   ...       0   \n",
       "5            5   1   104    84  1242  0    0     2    0    0   ...       0   \n",
       "6            0   0     0     0     0  2    0     0    0    0   ...       0   \n",
       "9            0   0     0     0     0  0  304    49    2    0   ...       0   \n",
       "10           0   0     8     1     1  0   41  1320   62    0   ...       0   \n",
       "11           0   0     0     0     0  0    2   202  405    0   ...       0   \n",
       "12           0   0     0     0     0  0    0     0    0  136   ...       0   \n",
       "13           0   0     0     0     0  0    0     0    0    1   ...       0   \n",
       "14           0   0     0     0     0  0    0     0    0    2   ...       0   \n",
       "15           0   0     1     0     0  0    1     0    0    0   ...       0   \n",
       "16           0   0     0     0     0  0    1     0    0    0   ...       0   \n",
       "17           0   0     5     1     1  0    0     2    0    0   ...       0   \n",
       "18           0   0     0     0     2  0    0     0    0    0   ...       0   \n",
       "19           1   0     2     1     3  0    0     0    0    0   ...       0   \n",
       "20           0   0     1     0     0  0    1     0    0    6   ...       0   \n",
       "21           0   0     0     0     1  0    1     0    0    0   ...       0   \n",
       "22           0   0     0     0     0  0    0     0    0    0   ...       0   \n",
       "23           0   0     0     0     4  0    0     0    0    0   ...       0   \n",
       "24           0   0     0     0     0  0    0     0    0    0   ...       0   \n",
       "25           0   0     0     0     0  0    0     0    0    0   ...       0   \n",
       "26           0   0     0     0     0  0    0     0    0    0   ...       0   \n",
       "27           0   0     0     0     2  0    0     0    0    0   ...       0   \n",
       "28           0   0     0     0     0  0    0     0    0    0   ...       0   \n",
       "29           0   0     0     0     0  0    0     0    0    0   ...       0   \n",
       "30           0   0     0     0     1  0    3     2    0    0   ...       0   \n",
       "31           0   0     0     0     0  0    1     0    0    0   ...       0   \n",
       "32           0   0     5     0     0  0    0     0    0    0   ...       0   \n",
       "...        ...  ..   ...   ...   ... ..  ...   ...  ...  ...   ...     ...   \n",
       "367          0   0     0     0     0  0    0     0    0    0   ...       0   \n",
       "368          0   0     0     0     0  0    0     0    0    0   ...       0   \n",
       "369          1   0     2     0     0  0    0     0    0    0   ...       0   \n",
       "373          0   0     0     0     0  0    0     0    0    0   ...       0   \n",
       "376          0   0     1     0     0  0    0     0    0    0   ...       0   \n",
       "377          0   0     0     0     0  0    0     0    0    0   ...       0   \n",
       "378          0   0     0     0     0  0    0     0    0    0   ...       0   \n",
       "379          0   0     0     0     0  0    0     0    0    0   ...       0   \n",
       "380          0   0     0     0     0  0    0     0    0    0   ...       0   \n",
       "381          0   0     0     0     0  0    0     0    0    0   ...       0   \n",
       "382          0   0     0     0     0  0    0     0    0    0   ...       5   \n",
       "383          0   0     0     0     0  0    0     0    0    0   ...       0   \n",
       "384          0   0     0     0     0  0    0     0    0    0   ...       0   \n",
       "385          0   0     0     0     0  0    0     0    0    0   ...       0   \n",
       "386          0   0     0     0     0  0    0     0    0    0   ...       0   \n",
       "387          0   0     0     0     0  0    0     0    0    0   ...       6   \n",
       "388          0   0     0     0     0  0    0     1    0    0   ...       0   \n",
       "389          0   0     0     0     0  0    0     0    0    0   ...    1353   \n",
       "390          0   0     0     0     1  0    0     1    0    0   ...      45   \n",
       "391          0   0     0     0     0  0    0     0    0    0   ...       0   \n",
       "392          0   0     1     0     0  0    0     0    0    0   ...     394   \n",
       "393          0   0     1     0     0  0    0     1    0    0   ...       0   \n",
       "394          0   0     0     0     0  0    0     0    0    0   ...       0   \n",
       "395          0   0     0     0     0  0    0     0    0    0   ...       1   \n",
       "396          0   0     0     0     0  0    0     0    0    0   ...       0   \n",
       "397          0   0     0     0     0  0    0     0    0    0   ...       0   \n",
       "398          0   0     0     0     0  0    0     0    0    0   ...       0   \n",
       "399          0   0     0     0     0  0    0     0    0    0   ...       0   \n",
       "403          0   0     0     0     0  0    0     0    0    0   ...       0   \n",
       "All        147  17  1606  1061  1723  3  371  1642  480  145   ...    1838   \n",
       "\n",
       "Predicted   390   392  393  394   395   396  397  403     All  \n",
       "True                                                           \n",
       "1             0     0    0    0     0     0    0    0     160  \n",
       "2             0     0    0    0     0     0    0    0      32  \n",
       "3             0     0    0    0     0     0    0    0    1490  \n",
       "4             0     0    0    0     0     0    0    0    1424  \n",
       "5             1     0    0    1     0     0    0    0    1508  \n",
       "6             0     0    0    0     0     0    0    0       3  \n",
       "9             0     0    0    0     0     0    0    0     361  \n",
       "10            0     1    0    0     0     0    0    0    1464  \n",
       "11            0     0    0    0     0     0    0    0     618  \n",
       "12            0     0    0    0     0     0    0    0     144  \n",
       "13            0     0    0    0     0     0    0    0      54  \n",
       "14            0     0    0    0     0     0    0    0      82  \n",
       "15            0     0    0    0     0     0    0    0    1493  \n",
       "16            0     0    0    0     0     0    0    0    1541  \n",
       "17            0     0    0    0     0     0    0    0    1466  \n",
       "18            0     0    0    0     0     0    0    0    1417  \n",
       "19            0     0    0    0     0     0    0    0    1574  \n",
       "20            0     0    0    0     0     0    0    0    1517  \n",
       "21            0     0    0    0     0     0    0    0    1529  \n",
       "22            0     0    0    0     0     0    0    0    1452  \n",
       "23            1     0    0    0     0     0    0    0    1540  \n",
       "24            0     0    0    0     0     0    0    0    1470  \n",
       "25            0     0    0    0     0     0    0    0    1308  \n",
       "26            0     0    0    0     0     0    0    0    1556  \n",
       "27            0     0    0    0     0     0    0    0    1480  \n",
       "28            0     0    0    0     0     0    0    0    1071  \n",
       "29            0     0    0    0     0     0    0    0       1  \n",
       "30            0     0    0    0     0     0    0    0    1451  \n",
       "31            0     0    0    0     0     0    0    0    1472  \n",
       "32            0     1    0    0     0     0    0    0    1537  \n",
       "...         ...   ...  ...  ...   ...   ...  ...  ...     ...  \n",
       "367           0     0    0    0     0     0    0    0       9  \n",
       "368           0     0    0    0     0     0    0    0       9  \n",
       "369           1     0    0    0     0     0    0    0    1472  \n",
       "373           0     0    0    0     0     0    0    0     819  \n",
       "376           1     0    0    1     0     0    0    0     665  \n",
       "377           0     0    0    0     0     0    0    0       1  \n",
       "378           0     0    0    0     0     0    0    0    1513  \n",
       "379           0     0    0    0     0     0    0    0     286  \n",
       "380           0     1    0    0     0     0    0    0     648  \n",
       "381           1     0    0    0     0     0    0    0     422  \n",
       "382          16    16    1    2     3     0    1    0    1483  \n",
       "383           2     0    0    0     0     0    0    0    1205  \n",
       "384           0     0    0    0     0     0    0    0       5  \n",
       "385           2     0    1    1     1     0    0    0    1343  \n",
       "386           5     2    0    0     0     0    1    0    1529  \n",
       "387           1     1    0    0     0     1    0    0    1461  \n",
       "388          10     1    0    0     0     0    0    0    1541  \n",
       "389          26   112    0    0     2     0    0    0    1523  \n",
       "390         947   326    0    0     2     0    0    0    1498  \n",
       "391           0     0    0    0     1     0    0    0       1  \n",
       "392         270   759    0    0     0     1    0    0    1492  \n",
       "393           0     0  488    1     8     0    0    0     537  \n",
       "394           1     1    1  844     7     2    2    0     870  \n",
       "395           1     0    5    2  1391    12    2    0    1462  \n",
       "396           0     0    0    6    10  1244    0    0    1282  \n",
       "397           0     0    0    1     1     0  428    0     437  \n",
       "398           0     0    0    0     0     0    0    0       1  \n",
       "399           0     0    0    0     0     0    0    0       1  \n",
       "403           0     0    0    0     0     0    0    1      36  \n",
       "All        1384  1258  535  865  1456  1267  438    7  284293  \n",
       "\n",
       "[363 rows x 323 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pd.crosstab(pd.Series(y_test_ary.ravel()), pd.Series(predictions_rnd.ravel()), rownames=['True'], colnames=['Predicted'], margins=True)\n",
    "pd.crosstab(pd.Series(np_utils.categorical_probas_to_classes(y_test_ary)), pd.Series(predictions), rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>78363</td>\n",
       "      <td>103</td>\n",
       "      <td>78466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102</td>\n",
       "      <td>1493</td>\n",
       "      <td>1595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>78465</td>\n",
       "      <td>1596</td>\n",
       "      <td>80061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0.0   1.0    All\n",
       "True                         \n",
       "0          78363   103  78466\n",
       "1            102  1493   1595\n",
       "All        78465  1596  80061"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(pd.Series(np_utils.categorical_probas_to_classes(y_test_ary)), pd.Series(predictions.ravel()), rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#model.get_config()\n",
    "def prediction_to_str(clf_prediction, category_id):\n",
    "    if(clf_prediction > 0.5):\n",
    "        return str(category_id)\n",
    "    else:\n",
    "        return 'not ' + str(category_id)\n",
    "\n",
    "def predict(description_str, tok_, clf_, max_length_, category_id_):\n",
    "    #seq_ = tok_.texts_to_sequences([description_str])\n",
    "    seq_ = texts_to_sequences_custom([description_str.lower()], tok_.word_index)\n",
    "    seq_pad = sequence.pad_sequences(seq_, maxlen = max_length_)\n",
    "    clf_prediction = clf_.predict(seq_pad)\n",
    "    \n",
    "    #print(seq_)\n",
    "    #print(seq_pad)\n",
    "    \n",
    "    # Prediction to string\n",
    "    clf_prediction_str = prediction_to_str(clf_prediction[0][0], category_id_)\n",
    "    \n",
    "    return clf_prediction_str\n",
    "    #return clf_prediction[0][0]\n",
    "\n",
    "def predict_2(description_str, tok_, clf_, max_length_, category_id_):\n",
    "    #seq_ = tok_.texts_to_sequences([description_str])\n",
    "    seq_ = texts_to_sequences_custom([description_str.lower()], tok_.word_index)\n",
    "    seq_pad = sequence.pad_sequences(seq_, maxlen = max_length_)\n",
    "    #clf_prediction = clf_.predict(seq_pad)\n",
    "    clf_prediction = model.predict_classes(seq_pad)\n",
    "    \n",
    "    #print(seq_)\n",
    "    #print(seq_pad)\n",
    "    \n",
    "    # Prediction to string\n",
    "    #clf_prediction_str = prediction_to_str(clf_prediction[0][0], category_id_)\n",
    "    clf_prediction = le.inverse_transform(clf_prediction)\n",
    "    \n",
    "    if(clf_prediction == ['Positive']):\n",
    "        return str(category_id_)\n",
    "    else:\n",
    "        return 'not ' + str(category_id_)\n",
    "    \n",
    "    \n",
    "def predict_proba(description_str, tok_, clf_, max_length_):\n",
    "    #seq_ = tok_.texts_to_sequences([description_str])\n",
    "    seq_ = texts_to_sequences_custom([description_str], tok_.word_index)\n",
    "    seq_pad = sequence.pad_sequences(seq_, maxlen = max_length_)\n",
    "    clf_prediction_proba = clf_.predict_proba(seq_pad, verbose=0)\n",
    "    \n",
    "    return clf_prediction_proba[0][0]\n",
    "\n",
    "\n",
    "# id_ = 'table Setr'\n",
    "# p = predict(id_, best_model_aux['Tokenizer'], best_model, best_model_aux['Max length'], best_model_aux['Category ID'])\n",
    "# pp = predict_proba(id_, best_model_aux['Tokenizer'], best_model, best_model_aux['Max length'])\n",
    "# print(p)\n",
    "# print(pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ====================================================================================================\n",
      "Old model prediction:\n",
      "item: tekton 2655 flare nut wrench set metric 6piece\n",
      "Seq max len: 30\n",
      "not 927\n",
      "4.17323e-08\n",
      "\n",
      "Fresh model prediction:\n",
      "item: tekton 2655 flare nut wrench set metric 6piece\n",
      "Seq max len: 30\n",
      "1/1 [==============================] - 0s\n",
      "not 927\n",
      "\n",
      "1 ====================================================================================================\n",
      "Old model prediction:\n",
      "item: tekton 2780 10slot screwdriver holder and organizer\n",
      "Seq max len: 30\n",
      "not 927\n",
      "0.121584\n",
      "\n",
      "Fresh model prediction:\n",
      "item: tekton 2780 10slot screwdriver holder and organizer\n",
      "Seq max len: 30\n",
      "1/1 [==============================] - 0s\n",
      "927\n",
      "\n",
      "2 ====================================================================================================\n",
      "Old model prediction:\n",
      "item: titan 17237 insulated electrical screwdriver set  7 piece\n",
      "Seq max len: 30\n",
      "927\n",
      "0.998989\n",
      "\n",
      "Fresh model prediction:\n",
      "item: titan 17237 insulated electrical screwdriver set  7 piece\n",
      "Seq max len: 30\n",
      "1/1 [==============================] - 0s\n",
      "927\n",
      "\n",
      "3 ====================================================================================================\n",
      "Old model prediction:\n",
      "item: tool sorter screwdriver organizer red\n",
      "Seq max len: 30\n",
      "not 927\n",
      "0.405264\n",
      "\n",
      "Fresh model prediction:\n",
      "item: tool sorter screwdriver organizer red\n",
      "Seq max len: 30\n",
      "1/1 [==============================] - 0s\n",
      "927\n",
      "\n",
      "4 ====================================================================================================\n",
      "Old model prediction:\n",
      "item: torin sdh15rt magnetic screwdriver holder\n",
      "Seq max len: 30\n",
      "927\n",
      "0.994613\n",
      "\n",
      "Fresh model prediction:\n",
      "item: torin sdh15rt magnetic screwdriver holder\n",
      "Seq max len: 30\n",
      "1/1 [==============================] - 0s\n",
      "927\n",
      "\n",
      "5 ====================================================================================================\n",
      "Old model prediction:\n",
      "item: wera 05020013001 joker combination wrenchset 11 pieces\n",
      "Seq max len: 30\n",
      "not 927\n",
      "0.0210169\n",
      "\n",
      "Fresh model prediction:\n",
      "item: wera 05020013001 joker combination wrenchset 11 pieces\n",
      "Seq max len: 30\n",
      "1/1 [==============================] - 0s\n",
      "not 927\n",
      "\n",
      "6 ====================================================================================================\n",
      "Old model prediction:\n",
      "item: wera kk vde 60i62i68i18 insulated pouch set with interchangeable blades 18piece\n",
      "Seq max len: 30\n",
      "927\n",
      "0.995252\n",
      "\n",
      "Fresh model prediction:\n",
      "item: wera kk vde 60i62i68i18 insulated pouch set with interchangeable blades 18piece\n",
      "Seq max len: 30\n",
      "1/1 [==============================] - 0s\n",
      "927\n",
      "\n",
      "7 ====================================================================================================\n",
      "Old model prediction:\n",
      "item: wiha 28103 magnetic 14 bit holder stubby 57mm pliers screwdriver\n",
      "Seq max len: 30\n",
      "927\n",
      "0.972863\n",
      "\n",
      "Fresh model prediction:\n",
      "item: wiha 28103 magnetic 14 bit holder stubby 57mm pliers screwdriver\n",
      "Seq max len: 30\n",
      "1/1 [==============================] - 0s\n",
      "927\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TEST\n",
    "\n",
    "## load old model\n",
    "model_file = \"category_927_nets__traindata5000_vectrain5000_model.h5\"\n",
    "aux_file = \"category_927_nets__traindata5000_vectrain5000_aux.pkl\"\n",
    "old_best_model_ = load_model(model_file)\n",
    "old_best_model_aux_ = get_model_file_aux(aux_file)\n",
    "old_tok_ = old_best_model_aux_['Tokenizer']\n",
    "old_word_index_ = old_best_model_aux_['Tokenizer'].word_index\n",
    "\n",
    "## use fresh model\n",
    "best_model_ = best_model\n",
    "best_model_aux_ = best_model_aux\n",
    "tok_ = tok\n",
    "word_index_ = word_index\n",
    "\n",
    "item_d = 'NieR: Automata™ DEMO 120161128 (Playable Demo)'\n",
    "\n",
    "# screwdrivers check\n",
    "scrw_items = [\n",
    "\"tekton 2655 flare nut wrench set metric 6piece\"\n",
    ",\"tekton 2780 10slot screwdriver holder and organizer\"\n",
    ",\"titan 17237 insulated electrical screwdriver set  7 piece\"\n",
    ",\"tool sorter screwdriver organizer red\"\n",
    ",\"torin sdh15rt magnetic screwdriver holder\"  #wrong predict\n",
    ",\"wera 05020013001 joker combination wrenchset 11 pieces\"\n",
    ",\"wera kk vde 60i62i68i18 insulated pouch set with interchangeable blades 18piece\" # tricky\n",
    ",\"wiha 28103 magnetic 14 bit holder stubby 57mm pliers screwdriver\" # tricky, wrong predict\n",
    "]\n",
    "\n",
    "for n, i in enumerate(scrw_items):\n",
    "    item_d = i\n",
    "    \n",
    "    print(str(n) + ' ' + '='*100)\n",
    "    \n",
    "    print('Old model prediction:')\n",
    "    print('item:',item_d)\n",
    "    print('Seq max len:', old_best_model_aux_['Max length'])\n",
    "    print(predict(item_d, old_tok_, old_best_model_, old_best_model_aux_['Max length'], '927'))\n",
    "    print(predict_proba(item_d, old_tok_, old_best_model_, old_best_model_aux_['Max length']))\n",
    "\n",
    "\n",
    "    print('\\nFresh model prediction:')\n",
    "    print('item:',item_d)\n",
    "    print('Seq max len:', best_model_aux_['Max length'])\n",
    "    print(predict_2(item_d, tok_, best_model_, best_model_aux_['Max length'], '927'))\n",
    "    #print(predict_proba(item_d, tok_, best_model_, best_model_aux_['Max length']))\n",
    "\n",
    "    print()\n",
    "\n",
    "    #tt = train_df.loc[0:10,['description_mod1']]\n",
    "    #tt['pred'] = tt['description_mod1'].apply(lambda x: predict(x, best_model_aux_['Tokenizer'], best_model, best_model_aux_['Max length'], best_model_aux_['Category ID']))\n",
    "    #tt['prob'] = tt['description_mod1'].apply(lambda x: predict_proba(x, best_model_aux_['Tokenizer'], best_model, best_model_aux_['Max length']))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
