{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.datasets import reuters\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import LSTM\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.text import Tokenizer, one_hot, text_to_word_sequence\n",
    "from keras.preprocessing import sequence\n",
    "from keras.layers.embeddings import Embedding\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Functions\n",
    "\n",
    "def get_word2index(texts_ls_):\n",
    "    word2index_ = {}\n",
    "\n",
    "    c = 1\n",
    "    for text_str in texts_ls_:\n",
    "        text_tokens_ls = text_str.lower().split()\n",
    "        for token in text_tokens_ls:\n",
    "            if(token not in word2index_):\n",
    "                word2index_[token] = c\n",
    "                c = c + 1\n",
    "                \n",
    "    return word2index_\n",
    "\n",
    "def train_df_preprocess(top_words_, texts_ls_, max_pad_length_):\n",
    "    # texts_ls_: list of texts strings\n",
    "    \n",
    "    tok = Tokenizer(top_words_)\n",
    "    tok.fit_on_texts(texts_ls_)\n",
    "\n",
    "    words = []\n",
    "    for iter in range(top_words):\n",
    "        words += [key for key,value in tok.word_index.items() if value==iter+1]\n",
    "\n",
    "    #Class for vectorizing texts, or/and turning texts into sequences \n",
    "    #(=list of word indexes, where the word of rank i in the dataset (starting at 1) has index i).\n",
    "    texts_vec_ls = tok.texts_to_sequences(texts_ls_)#turns text to sequence, stating which word comes in what place\n",
    "    texts_vec_mtx = sequence.pad_sequences(texts_vec_ls, maxlen=max_pad_length_)#pad sequence, essentially padding it with 0's at the end\n",
    "    \n",
    "    return texts_vec_mtx\n",
    "\n",
    "def text_2_vec(text_str, word2index_):\n",
    "    # text_str: text string\n",
    "    \n",
    "    text_tokens_ls = text_str.lower().split()\n",
    "    \n",
    "    text_vec = []\n",
    "    for token in text_tokens_ls:\n",
    "        if token in word2index_:\n",
    "            text_vec.append(word2index_[token])\n",
    "        else:\n",
    "            text_vec.append(0)\n",
    "            \n",
    "    return text_vec\n",
    "\n",
    "def train_df_preprocess_2(texts_ls_, word2index_, max_pad_length_):\n",
    "    # texts_ls_: list of texts strings\n",
    "    \n",
    "    texts_vec_ls = []\n",
    "    for text_ in texts_ls_:\n",
    "        #print(text_)\n",
    "        #print(type(text_))\n",
    "        text_vec = text_2_vec(text_, word2index_)\n",
    "        texts_vec_ls.append(text_vec)\n",
    "    \n",
    "    texts_vec_ary = sequence.pad_sequences(texts_vec_ls, maxlen=max_pad_length_)\n",
    "    \n",
    "    return texts_vec_ary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data shape: (6822, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_mod1</th>\n",
       "      <th>category_id_mod1</th>\n",
       "      <th>category_full_path_mod1</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RION TECH 5 point 6 point 3 Piece Tool Kit Pen...</td>\n",
       "      <td>927</td>\n",
       "      <td>Tools &amp; Home Improvement &gt; Power &amp; Hand Tools ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stalwart 25-piece 4.8V Cordless Screwdriver Set</td>\n",
       "      <td>927</td>\n",
       "      <td>Tools &amp; Home Improvement &gt; Power &amp; Hand Tools ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    description_mod1  category_id_mod1  \\\n",
       "0  RION TECH 5 point 6 point 3 Piece Tool Kit Pen...               927   \n",
       "1    Stalwart 25-piece 4.8V Cordless Screwdriver Set               927   \n",
       "\n",
       "                             category_full_path_mod1    target  \n",
       "0  Tools & Home Improvement > Power & Hand Tools ...  Positive  \n",
       "1  Tools & Home Improvement > Power & Hand Tools ...     False  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read train set (screwdrivers)\n",
    "pkl_file = '/Users/altay.amanbay/Desktop/new node booster/experiments/2.1/train_data.pkl'\n",
    "train_df = pd.read_pickle(pkl_file)\n",
    "\n",
    "# Create target feature\n",
    "train_df['target'] = train_df['type'].apply(lambda x: 'False' if x == 'False Positive' else 'Positive')\n",
    "\n",
    "# Drop index column\n",
    "train_df.drop(labels=['type'], axis=1, inplace=True)\n",
    "\n",
    "# Encode target feature\n",
    "#le = LabelEncoder()\n",
    "#le.fit(train_df['target'])\n",
    "#train_df['target_le'] = le.transform(train_df['target'])\n",
    "\n",
    "\n",
    "# cat = 'Tools & Home Improvement > Power & Hand Tools > Hand Tools > Screwdrivers'\n",
    "# positives, negatives = get_positives_negatives(train_df, cat)\n",
    "# X_train = input_text = pd.concat([positives, negatives])\n",
    "# y_train = [1] * len(positives) + [0] * len(negatives)\n",
    "\n",
    "print('train data shape:',train_df.shape)\n",
    "train_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples data shape: (9722, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_mod1</th>\n",
       "      <th>category_id_mod1</th>\n",
       "      <th>category_full_path_mod1</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>!iT Jeans Maternity Skinny Jeans Dark Wash M</td>\n",
       "      <td>100</td>\n",
       "      <td>Apparel &amp; Accessories &gt; Apparel &gt; Maternity</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Citizens of Humanity Avedon Skinny Maternity A...</td>\n",
       "      <td>100</td>\n",
       "      <td>Apparel &amp; Accessories &gt; Apparel &gt; Maternity</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DL1961 Maternity Angel Jeans - Riker-30</td>\n",
       "      <td>100</td>\n",
       "      <td>Apparel &amp; Accessories &gt; Apparel &gt; Maternity</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>James Jeans - Twiggy Maternity Legging in Dark...</td>\n",
       "      <td>100</td>\n",
       "      <td>Apparel &amp; Accessories &gt; Apparel &gt; Maternity</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>James Jeans Twiggy Maternity Under Belly Pull ...</td>\n",
       "      <td>100</td>\n",
       "      <td>Apparel &amp; Accessories &gt; Apparel &gt; Maternity</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    description_mod1  category_id_mod1  \\\n",
       "0       !iT Jeans Maternity Skinny Jeans Dark Wash M               100   \n",
       "1  Citizens of Humanity Avedon Skinny Maternity A...               100   \n",
       "2            DL1961 Maternity Angel Jeans - Riker-30               100   \n",
       "3  James Jeans - Twiggy Maternity Legging in Dark...               100   \n",
       "4  James Jeans Twiggy Maternity Under Belly Pull ...               100   \n",
       "\n",
       "                       category_full_path_mod1 target  \n",
       "0  Apparel & Accessories > Apparel > Maternity  False  \n",
       "1  Apparel & Accessories > Apparel > Maternity  False  \n",
       "2  Apparel & Accessories > Apparel > Maternity  False  \n",
       "3  Apparel & Accessories > Apparel > Maternity  False  \n",
       "4  Apparel & Accessories > Apparel > Maternity  False  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read sampled descriptionary\n",
    "\n",
    "path = '/Users/altay.amanbay/Desktop/new node booster/experiments/Sampling nodes from descriptionary/3 - Picking samples from each node/sampled descriptionary/'\n",
    "file_name = 'sampled_descriptionary_sample_size_30.csv'\n",
    "samples_df = pd.read_csv(path + file_name)\n",
    "\n",
    "# Rename columns\n",
    "samples_df.rename(columns={'description': 'description_mod1', \n",
    "                           'category_id': 'category_id_mod1',\n",
    "                           'category_path': 'category_full_path_mod1'}, inplace=True)\n",
    "\n",
    "# Drop 'screwdrivers' from descriptionary\n",
    "samples_df = samples_df.loc[samples_df.category_id_mod1 != 927,:]\n",
    "\n",
    "# Drop index column\n",
    "samples_df.drop(labels=['index'], axis=1, inplace=True)\n",
    "\n",
    "# Add target column and make all false as all items are not screwdrivers\n",
    "samples_df['target'] = 'False'\n",
    "\n",
    "print('samples data shape:',samples_df.shape)\n",
    "samples_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data shape: (16544, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_mod1</th>\n",
       "      <th>category_id_mod1</th>\n",
       "      <th>category_full_path_mod1</th>\n",
       "      <th>target</th>\n",
       "      <th>target_le</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RION TECH 5 point 6 point 3 Piece Tool Kit Pen...</td>\n",
       "      <td>927</td>\n",
       "      <td>Tools &amp; Home Improvement &gt; Power &amp; Hand Tools ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stalwart 25-piece 4.8V Cordless Screwdriver Set</td>\n",
       "      <td>927</td>\n",
       "      <td>Tools &amp; Home Improvement &gt; Power &amp; Hand Tools ...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    description_mod1  category_id_mod1  \\\n",
       "0  RION TECH 5 point 6 point 3 Piece Tool Kit Pen...               927   \n",
       "1    Stalwart 25-piece 4.8V Cordless Screwdriver Set               927   \n",
       "\n",
       "                             category_full_path_mod1    target  target_le  \n",
       "0  Tools & Home Improvement > Power & Hand Tools ...  Positive          1  \n",
       "1  Tools & Home Improvement > Power & Hand Tools ...     False          0  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concat original train set and sampled descriptionary\n",
    "train_df = pd.concat([train_df,samples_df], axis=0)\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Encode target feature\n",
    "le = LabelEncoder()\n",
    "le.fit(train_df['target'])\n",
    "train_df['target_le'] = le.transform(train_df['target'])\n",
    "\n",
    "\n",
    "print('train data shape:',train_df.shape)\n",
    "train_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'numpy.ndarray'>\n",
      "11580\n",
      "4964\n",
      "(11580,)\n",
      "(4964,)\n"
     ]
    }
   ],
   "source": [
    "# Split into train and test\n",
    "#X = train_df.loc[:,['description_mod1']]\n",
    "X_ls = list(train_df['description_mod1'])\n",
    "y_ary = np.array(list(train_df['target_le']))\n",
    "print(type(X_ls))\n",
    "print(type(y_ary))\n",
    "\n",
    "X_train_ls, X_test_ls, y_train_ary, y_test_ary = train_test_split(X_ls, y_ary, test_size = 0.3)\n",
    "\n",
    "# print(X_train_df.shape)\n",
    "# print(X_test_df.shape)\n",
    "print(len(X_train_ls))\n",
    "print(len(X_test_ls))\n",
    "print(y_train_ary.shape)\n",
    "print(y_test_ary.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_texts_vec_mtx shape: (11580, 30)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['drivers', 'tr', 'sconce', 'frappe', 'dinner']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert train set into sequences for nets\n",
    "\n",
    "top_words = 20000\n",
    "max_description_length = 30\n",
    "\n",
    "tok = Tokenizer(nb_words = top_words)\n",
    "tok.fit_on_texts(X_train_ls)\n",
    "word_index = tok.word_index\n",
    "\n",
    "train_texts_vec_ls = tok.texts_to_sequences(X_train_ls)\n",
    "train_texts_vec_mtx = sequence.pad_sequences(train_texts_vec_ls, maxlen = max_description_length)\n",
    "\n",
    "print('train_texts_vec_mtx shape:',train_texts_vec_mtx.shape)\n",
    "list(tok.word_index)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert test set into sequences for nets\n",
    "\n",
    "test_texts_vec_ls = tok.texts_to_sequences(X_test_ls)\n",
    "test_texts_vec_mtx = sequence.pad_sequences(test_texts_vec_ls, maxlen = max_description_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word index size: 5500\n",
      "embedding matrix shape: (5501, 32)\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.43000128  0.86506031  0.83779409  0.24633669  0.57024406  0.82124156\n",
      "  0.72401312  0.65143898  0.46307937  0.53842921  0.5821674   0.56437874\n",
      "  0.51761817  0.21353142  0.55181363  0.58230838  0.13797185  0.81335379\n",
      "  0.74359554  0.9659438   0.4794416   0.85213847  0.16980623  0.45701813\n",
      "  0.67093386  0.94342833  0.57794982  0.2044182   0.62356217  0.61968723\n",
      "  0.38667406  0.24876632]\n"
     ]
    }
   ],
   "source": [
    "# Create embedding vectors for each word in word index\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(7)\n",
    "\n",
    "embedding_vecor_length = 32\n",
    "uniq_token_count = len(tok.word_index)\n",
    "print('word index size:', uniq_token_count)\n",
    "\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, embedding_vecor_length))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = np.random.uniform(.1, size=(1, 32))\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "print('embedding matrix shape:',embedding_matrix.shape)\n",
    "print(embedding_matrix[0])\n",
    "print(embedding_matrix[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_5 (Embedding)          (None, 30, 32)        176032      embedding_input_5[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "lstm_5 (LSTM)                    (None, 10)            1720        embedding_5[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                  (None, 1)             11          lstm_5[0][0]                     \n",
      "====================================================================================================\n",
      "Total params: 177,763\n",
      "Trainable params: 177,763\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "Train on 4775 samples, validate on 2047 samples\n",
      "Epoch 1/10\n",
      "4775/4775 [==============================] - 12s - loss: 0.4947 - acc: 0.7684 - val_loss: 0.3976 - val_acc: 0.7782\n",
      "Epoch 2/10\n",
      "4775/4775 [==============================] - 10s - loss: 0.3021 - acc: 0.8714 - val_loss: 0.2702 - val_acc: 0.8876\n",
      "Epoch 3/10\n",
      "4775/4775 [==============================] - 10s - loss: 0.1908 - acc: 0.9405 - val_loss: 0.2188 - val_acc: 0.9160\n",
      "Epoch 4/10\n",
      "4775/4775 [==============================] - 10s - loss: 0.1416 - acc: 0.9590 - val_loss: 0.2044 - val_acc: 0.9209\n",
      "Epoch 5/10\n",
      "4775/4775 [==============================] - 10s - loss: 0.1040 - acc: 0.9736 - val_loss: 0.2016 - val_acc: 0.9204\n",
      "Epoch 6/10\n",
      "4775/4775 [==============================] - 11s - loss: 0.0757 - acc: 0.9820 - val_loss: 0.2099 - val_acc: 0.9228\n",
      "Epoch 7/10\n",
      "4775/4775 [==============================] - 11s - loss: 0.0614 - acc: 0.9855 - val_loss: 0.2030 - val_acc: 0.9248\n",
      "Epoch 8/10\n",
      "4775/4775 [==============================] - 11s - loss: 0.0528 - acc: 0.9879 - val_loss: 0.2216 - val_acc: 0.9199\n",
      "Epoch 9/10\n",
      "4775/4775 [==============================] - 11s - loss: 0.0451 - acc: 0.9893 - val_loss: 0.1860 - val_acc: 0.9292\n",
      "Epoch 10/10\n",
      "4775/4775 [==============================] - 11s - loss: 0.0414 - acc: 0.9899 - val_loss: 0.2178 - val_acc: 0.9243\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12a21a710>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model\n",
    "#embedding_vecor_length = 32\n",
    "top_words = len(word_index) + 1\n",
    "batch_size_ = 25 #64\n",
    "\n",
    "model = Sequential()\n",
    "#model.add(Embedding(top_words, embedding_vecor_length, input_length = max_description_length))\n",
    "embedding_layer = Embedding(top_words, \n",
    "                            embedding_vecor_length, \n",
    "                            weights=[embedding_matrix], \n",
    "                            input_length = max_description_length,\n",
    "                            trainable=True)\n",
    "model.add(embedding_layer)\n",
    "model.add(LSTM(10))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "#model.layers[0].trainable = False\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "#model.fit(X_train_ary, y_train_ary, validation_data=(X_train_ary, y_train_ary), nb_epoch=5, batch_size=64)\n",
    "model.fit(train_texts_vec_mtx, y_train_ary, validation_data=(test_texts_vec_mtx, y_test_ary), nb_epoch=10, batch_size=batch_size_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'class_name': 'Embedding',\n",
       "  'config': {'W_constraint': None,\n",
       "   'W_regularizer': None,\n",
       "   'activity_regularizer': None,\n",
       "   'batch_input_shape': (None, 30),\n",
       "   'dropout': 0.0,\n",
       "   'init': 'uniform',\n",
       "   'input_dim': 5501,\n",
       "   'input_dtype': 'int32',\n",
       "   'input_length': 30,\n",
       "   'mask_zero': False,\n",
       "   'name': 'embedding_2',\n",
       "   'output_dim': 32,\n",
       "   'trainable': False}},\n",
       " {'class_name': 'LSTM',\n",
       "  'config': {'U_regularizer': None,\n",
       "   'W_regularizer': None,\n",
       "   'activation': 'tanh',\n",
       "   'b_regularizer': None,\n",
       "   'consume_less': 'cpu',\n",
       "   'dropout_U': 0.0,\n",
       "   'dropout_W': 0.0,\n",
       "   'forget_bias_init': 'one',\n",
       "   'go_backwards': False,\n",
       "   'init': 'glorot_uniform',\n",
       "   'inner_activation': 'hard_sigmoid',\n",
       "   'inner_init': 'orthogonal',\n",
       "   'input_dim': 32,\n",
       "   'input_length': None,\n",
       "   'name': 'lstm_2',\n",
       "   'output_dim': 100,\n",
       "   'return_sequences': False,\n",
       "   'stateful': False,\n",
       "   'trainable': True,\n",
       "   'unroll': False}},\n",
       " {'class_name': 'Dense',\n",
       "  'config': {'W_constraint': None,\n",
       "   'W_regularizer': None,\n",
       "   'activation': 'sigmoid',\n",
       "   'activity_regularizer': None,\n",
       "   'b_constraint': None,\n",
       "   'b_regularizer': None,\n",
       "   'bias': True,\n",
       "   'init': 'glorot_uniform',\n",
       "   'input_dim': 100,\n",
       "   'name': 'dense_2',\n",
       "   'output_dim': 1,\n",
       "   'trainable': True}}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set: 99.56%\n",
      "Accuracy on test set: 92.43%\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of the model\n",
    "scores = model.evaluate(train_texts_vec_mtx, y_train_ary, verbose=0)\n",
    "print(\"Accuracy on train set: %.2f%%\" % (scores[1]*100))\n",
    "\n",
    "scores = model.evaluate(test_texts_vec_mtx, y_test_ary, verbose=0)\n",
    "print(\"Accuracy on test set: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(test_texts_vec_mtx)\n",
    "predictions_rnd = np.round_(predictions, decimals=0, out=None)\n",
    "predictions_rnd[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# misc check\n",
    "# for i in range(predictions.shape[0]):\n",
    "#     if(np.round_(predictions[i], decimals=0, out=None) == 1):\n",
    "#         print(predictions[i])\n",
    "#         np.round_(predictions[i], decimals=0, out=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88</td>\n",
       "      <td>368</td>\n",
       "      <td>456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>297</td>\n",
       "      <td>1294</td>\n",
       "      <td>1591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>385</td>\n",
       "      <td>1662</td>\n",
       "      <td>2047</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted  0.0   1.0   All\n",
       "True                      \n",
       "0           88   368   456\n",
       "1          297  1294  1591\n",
       "All        385  1662  2047"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(pd.Series(y_train_ary.ravel()), pd.Series(predictions_rnd.ravel()), rownames=['True'], colnames=['Predicted'], margins=True)\n",
    "#pd.crosstab(pd.Series(y_test_ary.ravel()), pd.Series(predictions_rnd.ravel()), rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>398</td>\n",
       "      <td>80</td>\n",
       "      <td>478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63</td>\n",
       "      <td>1506</td>\n",
       "      <td>1569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>461</td>\n",
       "      <td>1586</td>\n",
       "      <td>2047</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted  0.0   1.0   All\n",
       "True                      \n",
       "0          398    80   478\n",
       "1           63  1506  1569\n",
       "All        461  1586  2047"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(pd.Series(y_test_ary.ravel()), pd.Series(predictions_rnd.ravel()), rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
